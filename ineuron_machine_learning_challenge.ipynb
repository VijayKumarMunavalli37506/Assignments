{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "ineuron_machine_learning_challenge.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VijayKumarMunavalli37506/Assignments/blob/master/ineuron_machine_learning_challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eQJPKK2zQ70",
        "colab_type": "text"
      },
      "source": [
        "## ineuron Competition for House Prices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ppWjuNFzQ78",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8118f881-d253-4a0b-bc2a-3d3b68a8bc80"
      },
      "source": [
        "# Import libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xan2sWFv6pGv",
        "colab_type": "text"
      },
      "source": [
        "**Upload the Excel to Colab**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6iQmaYnzQ8N",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "7d088ce6-1235-419d-fb19-9c67ac496430"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c317f5a6-5dae-44e4-b8d0-fbdca031d9e5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c317f5a6-5dae-44e4-b8d0-fbdca031d9e5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving housing_train.xlsx to housing_train.xlsx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZqirRX4zQ8g",
        "colab_type": "code",
        "colab": {},
        "outputId": "48250fb3-889f-4fdc-9657-0e64fdc84836"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>region</th>\n",
              "      <th>region_url</th>\n",
              "      <th>price</th>\n",
              "      <th>type</th>\n",
              "      <th>sqfeet</th>\n",
              "      <th>beds</th>\n",
              "      <th>baths</th>\n",
              "      <th>cats_allowed</th>\n",
              "      <th>...</th>\n",
              "      <th>wheelchair_access</th>\n",
              "      <th>electric_vehicle_charge</th>\n",
              "      <th>comes_furnished</th>\n",
              "      <th>laundry_options</th>\n",
              "      <th>parking_options</th>\n",
              "      <th>image_url</th>\n",
              "      <th>description</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7039061606</td>\n",
              "      <td>https://bham.craigslist.org/apa/d/birmingham-h...</td>\n",
              "      <td>birmingham</td>\n",
              "      <td>https://bham.craigslist.org</td>\n",
              "      <td>1195</td>\n",
              "      <td>apartment</td>\n",
              "      <td>1908</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>laundry on site</td>\n",
              "      <td>street parking</td>\n",
              "      <td>https://images.craigslist.org/00L0L_80pNkyDeG0...</td>\n",
              "      <td>Apartments In Birmingham AL Welcome to 100 Inv...</td>\n",
              "      <td>33.4226</td>\n",
              "      <td>-86.7065</td>\n",
              "      <td>al</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7041970863</td>\n",
              "      <td>https://bham.craigslist.org/apa/d/birmingham-w...</td>\n",
              "      <td>birmingham</td>\n",
              "      <td>https://bham.craigslist.org</td>\n",
              "      <td>1120</td>\n",
              "      <td>apartment</td>\n",
              "      <td>1319</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>laundry on site</td>\n",
              "      <td>off-street parking</td>\n",
              "      <td>https://images.craigslist.org/00707_uRrY9CsNMC...</td>\n",
              "      <td>Find Your Way to Haven Apartment Homes Come ho...</td>\n",
              "      <td>33.3755</td>\n",
              "      <td>-86.8045</td>\n",
              "      <td>al</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7041966914</td>\n",
              "      <td>https://bham.craigslist.org/apa/d/birmingham-g...</td>\n",
              "      <td>birmingham</td>\n",
              "      <td>https://bham.craigslist.org</td>\n",
              "      <td>825</td>\n",
              "      <td>apartment</td>\n",
              "      <td>1133</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>laundry on site</td>\n",
              "      <td>street parking</td>\n",
              "      <td>https://images.craigslist.org/00h0h_b7Bdj1NLBi...</td>\n",
              "      <td>Apartments In Birmingham AL Welcome to 100 Inv...</td>\n",
              "      <td>33.4226</td>\n",
              "      <td>-86.7065</td>\n",
              "      <td>al</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7041966936</td>\n",
              "      <td>https://bham.craigslist.org/apa/d/birmingham-f...</td>\n",
              "      <td>birmingham</td>\n",
              "      <td>https://bham.craigslist.org</td>\n",
              "      <td>800</td>\n",
              "      <td>apartment</td>\n",
              "      <td>927</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>laundry on site</td>\n",
              "      <td>street parking</td>\n",
              "      <td>https://images.craigslist.org/00808_6ghZ8tSRQs...</td>\n",
              "      <td>Apartments In Birmingham AL Welcome to 100 Inv...</td>\n",
              "      <td>33.4226</td>\n",
              "      <td>-86.7065</td>\n",
              "      <td>al</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7041966888</td>\n",
              "      <td>https://bham.craigslist.org/apa/d/birmingham-2...</td>\n",
              "      <td>birmingham</td>\n",
              "      <td>https://bham.craigslist.org</td>\n",
              "      <td>785</td>\n",
              "      <td>apartment</td>\n",
              "      <td>1047</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>laundry on site</td>\n",
              "      <td>street parking</td>\n",
              "      <td>https://images.craigslist.org/00y0y_21c0FOvUXm...</td>\n",
              "      <td>Apartments In Birmingham AL Welcome to 100 Inv...</td>\n",
              "      <td>33.4226</td>\n",
              "      <td>-86.7065</td>\n",
              "      <td>al</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id                                                url      region  \\\n",
              "0  7039061606  https://bham.craigslist.org/apa/d/birmingham-h...  birmingham   \n",
              "1  7041970863  https://bham.craigslist.org/apa/d/birmingham-w...  birmingham   \n",
              "2  7041966914  https://bham.craigslist.org/apa/d/birmingham-g...  birmingham   \n",
              "3  7041966936  https://bham.craigslist.org/apa/d/birmingham-f...  birmingham   \n",
              "4  7041966888  https://bham.craigslist.org/apa/d/birmingham-2...  birmingham   \n",
              "\n",
              "                    region_url  price       type  sqfeet  beds  baths  \\\n",
              "0  https://bham.craigslist.org   1195  apartment    1908     3    2.0   \n",
              "1  https://bham.craigslist.org   1120  apartment    1319     3    2.0   \n",
              "2  https://bham.craigslist.org    825  apartment    1133     1    1.5   \n",
              "3  https://bham.craigslist.org    800  apartment     927     1    1.0   \n",
              "4  https://bham.craigslist.org    785  apartment    1047     2    1.0   \n",
              "\n",
              "   cats_allowed  ...  wheelchair_access  electric_vehicle_charge  \\\n",
              "0             1  ...                  0                        0   \n",
              "1             1  ...                  0                        0   \n",
              "2             1  ...                  0                        0   \n",
              "3             1  ...                  0                        0   \n",
              "4             1  ...                  0                        0   \n",
              "\n",
              "   comes_furnished  laundry_options     parking_options  \\\n",
              "0                0  laundry on site      street parking   \n",
              "1                0  laundry on site  off-street parking   \n",
              "2                0  laundry on site      street parking   \n",
              "3                0  laundry on site      street parking   \n",
              "4                0  laundry on site      street parking   \n",
              "\n",
              "                                           image_url  \\\n",
              "0  https://images.craigslist.org/00L0L_80pNkyDeG0...   \n",
              "1  https://images.craigslist.org/00707_uRrY9CsNMC...   \n",
              "2  https://images.craigslist.org/00h0h_b7Bdj1NLBi...   \n",
              "3  https://images.craigslist.org/00808_6ghZ8tSRQs...   \n",
              "4  https://images.craigslist.org/00y0y_21c0FOvUXm...   \n",
              "\n",
              "                                         description      lat     long  state  \n",
              "0  Apartments In Birmingham AL Welcome to 100 Inv...  33.4226 -86.7065     al  \n",
              "1  Find Your Way to Haven Apartment Homes Come ho...  33.3755 -86.8045     al  \n",
              "2  Apartments In Birmingham AL Welcome to 100 Inv...  33.4226 -86.7065     al  \n",
              "3  Apartments In Birmingham AL Welcome to 100 Inv...  33.4226 -86.7065     al  \n",
              "4  Apartments In Birmingham AL Welcome to 100 Inv...  33.4226 -86.7065     al  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "O3WgKWwizQ84",
        "colab_type": "code",
        "colab": {},
        "outputId": "4d2cc84f-61ee-45c1-a69b-7b343f386b7a"
      },
      "source": [
        "df['price'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "750     2792\n",
              "850     2722\n",
              "1200    2714\n",
              "800     2680\n",
              "950     2467\n",
              "        ... \n",
              "7478       1\n",
              "151        1\n",
              "5175       1\n",
              "3276       1\n",
              "3631       1\n",
              "Name: price, Length: 3753, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzjWNnYBzQ9G",
        "colab_type": "code",
        "colab": {},
        "outputId": "35da50d9-e6ef-412b-d548-1a7a500bcc81"
      },
      "source": [
        "sns.heatmap(df.isnull(),yticklabels=False,cbar=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x250db2b2d88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW8pnrkzzQ9S",
        "colab_type": "code",
        "colab": {},
        "outputId": "69fa87d5-547b-494b-b0e4-d45fb97fc295"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(265190, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiXf-VgFzQ9j",
        "colab_type": "code",
        "colab": {},
        "outputId": "9a56f8ee-5a73-4967-b6db-4d394a649bf4"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                             0\n",
              "url                            0\n",
              "region                         0\n",
              "region_url                     0\n",
              "price                          0\n",
              "type                           0\n",
              "sqfeet                         0\n",
              "beds                           0\n",
              "baths                          0\n",
              "cats_allowed                   0\n",
              "dogs_allowed                   0\n",
              "smoking_allowed                0\n",
              "wheelchair_access              0\n",
              "electric_vehicle_charge        0\n",
              "comes_furnished                0\n",
              "laundry_options            54311\n",
              "parking_options            95135\n",
              "image_url                      0\n",
              "lat                         1419\n",
              "long                        1419\n",
              "state                          1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTCQ40FbzQ93",
        "colab_type": "code",
        "colab": {},
        "outputId": "dfa46dcc-d364-42c0-bdd0-6fc315ff91df"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 265190 entries, 0 to 265189\n",
            "Data columns (total 21 columns):\n",
            " #   Column                   Non-Null Count   Dtype  \n",
            "---  ------                   --------------   -----  \n",
            " 0   id                       265190 non-null  int64  \n",
            " 1   url                      265190 non-null  object \n",
            " 2   region                   265190 non-null  object \n",
            " 3   region_url               265190 non-null  object \n",
            " 4   price                    265190 non-null  int64  \n",
            " 5   type                     265190 non-null  object \n",
            " 6   sqfeet                   265190 non-null  int64  \n",
            " 7   beds                     265190 non-null  int64  \n",
            " 8   baths                    265190 non-null  float64\n",
            " 9   cats_allowed             265190 non-null  int64  \n",
            " 10  dogs_allowed             265190 non-null  int64  \n",
            " 11  smoking_allowed          265190 non-null  int64  \n",
            " 12  wheelchair_access        265190 non-null  int64  \n",
            " 13  electric_vehicle_charge  265190 non-null  int64  \n",
            " 14  comes_furnished          265190 non-null  int64  \n",
            " 15  laundry_options          210879 non-null  object \n",
            " 16  parking_options          170055 non-null  object \n",
            " 17  image_url                265190 non-null  object \n",
            " 18  lat                      263771 non-null  float64\n",
            " 19  long                     263771 non-null  float64\n",
            " 20  state                    265189 non-null  object \n",
            "dtypes: float64(3), int64(10), object(8)\n",
            "memory usage: 42.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B65tb4XRzQ-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(['region_url'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKFrR4KTzQ-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['lat']=df['lat'].fillna(df['lat'].mode()[0])\n",
        "df['long']=df['long'].fillna(df['long'].mode()[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPV4h3tQzQ-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['laundry_options']=df['laundry_options'].fillna(df['laundry_options'].mode()[0])\n",
        "df['parking_options']=df['parking_options'].fillna(df['parking_options'].mode()[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6_xX4a_zQ-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['state']=df['state'].fillna(df['state'].mode()[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0D7ZRH1zQ_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(['id'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37Ag5s0zzQ_Z",
        "colab_type": "code",
        "colab": {},
        "outputId": "69a55199-c38f-4702-80b0-5cc5136bb2fa"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(265190, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0BoO8PgzQ_p",
        "colab_type": "code",
        "colab": {},
        "outputId": "0a7b6d86-0de3-437c-bbba-ddacfa0f0be5"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "region                     0\n",
              "price                      0\n",
              "type                       0\n",
              "sqfeet                     0\n",
              "beds                       0\n",
              "baths                      0\n",
              "cats_allowed               0\n",
              "dogs_allowed               0\n",
              "smoking_allowed            0\n",
              "wheelchair_access          0\n",
              "electric_vehicle_charge    0\n",
              "comes_furnished            0\n",
              "laundry_options            0\n",
              "parking_options            0\n",
              "lat                        0\n",
              "long                       0\n",
              "state                      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7GO9HznzRAC",
        "colab_type": "code",
        "colab": {},
        "outputId": "a037e141-7545-4537-fd0b-23abeb9e763f"
      },
      "source": [
        "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='coolwarm')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x25105a3ce88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItjGMlm2zRAU",
        "colab_type": "code",
        "colab": {},
        "outputId": "2ff7d130-b911-4d8a-fb54-1db4ba403438"
      },
      "source": [
        "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='YlGnBu')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x250e922c288>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeWmdkrCzRAq",
        "colab_type": "code",
        "colab": {},
        "outputId": "502a3faa-245d-4e02-e811-baacc8c47e27"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(265190, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD5B7jLOzRA9",
        "colab_type": "code",
        "colab": {},
        "outputId": "72b99053-37c9-4a20-fceb-915dd1d49ca3"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>region</th>\n",
              "      <th>price</th>\n",
              "      <th>type</th>\n",
              "      <th>sqfeet</th>\n",
              "      <th>beds</th>\n",
              "      <th>baths</th>\n",
              "      <th>cats_allowed</th>\n",
              "      <th>dogs_allowed</th>\n",
              "      <th>smoking_allowed</th>\n",
              "      <th>wheelchair_access</th>\n",
              "      <th>electric_vehicle_charge</th>\n",
              "      <th>comes_furnished</th>\n",
              "      <th>laundry_options</th>\n",
              "      <th>parking_options</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>birmingham</td>\n",
              "      <td>1195</td>\n",
              "      <td>apartment</td>\n",
              "      <td>1908</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>laundry on site</td>\n",
              "      <td>street parking</td>\n",
              "      <td>33.4226</td>\n",
              "      <td>-86.7065</td>\n",
              "      <td>al</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>birmingham</td>\n",
              "      <td>1120</td>\n",
              "      <td>apartment</td>\n",
              "      <td>1319</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>laundry on site</td>\n",
              "      <td>off-street parking</td>\n",
              "      <td>33.3755</td>\n",
              "      <td>-86.8045</td>\n",
              "      <td>al</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>birmingham</td>\n",
              "      <td>825</td>\n",
              "      <td>apartment</td>\n",
              "      <td>1133</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>laundry on site</td>\n",
              "      <td>street parking</td>\n",
              "      <td>33.4226</td>\n",
              "      <td>-86.7065</td>\n",
              "      <td>al</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>birmingham</td>\n",
              "      <td>800</td>\n",
              "      <td>apartment</td>\n",
              "      <td>927</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>laundry on site</td>\n",
              "      <td>street parking</td>\n",
              "      <td>33.4226</td>\n",
              "      <td>-86.7065</td>\n",
              "      <td>al</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>birmingham</td>\n",
              "      <td>785</td>\n",
              "      <td>apartment</td>\n",
              "      <td>1047</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>laundry on site</td>\n",
              "      <td>street parking</td>\n",
              "      <td>33.4226</td>\n",
              "      <td>-86.7065</td>\n",
              "      <td>al</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       region  price       type  sqfeet  beds  baths  cats_allowed  \\\n",
              "0  birmingham   1195  apartment    1908     3    2.0             1   \n",
              "1  birmingham   1120  apartment    1319     3    2.0             1   \n",
              "2  birmingham    825  apartment    1133     1    1.5             1   \n",
              "3  birmingham    800  apartment     927     1    1.0             1   \n",
              "4  birmingham    785  apartment    1047     2    1.0             1   \n",
              "\n",
              "   dogs_allowed  smoking_allowed  wheelchair_access  electric_vehicle_charge  \\\n",
              "0             1                1                  0                        0   \n",
              "1             1                1                  0                        0   \n",
              "2             1                1                  0                        0   \n",
              "3             1                1                  0                        0   \n",
              "4             1                1                  0                        0   \n",
              "\n",
              "   comes_furnished  laundry_options     parking_options      lat     long  \\\n",
              "0                0  laundry on site      street parking  33.4226 -86.7065   \n",
              "1                0  laundry on site  off-street parking  33.3755 -86.8045   \n",
              "2                0  laundry on site      street parking  33.4226 -86.7065   \n",
              "3                0  laundry on site      street parking  33.4226 -86.7065   \n",
              "4                0  laundry on site      street parking  33.4226 -86.7065   \n",
              "\n",
              "  state  \n",
              "0    al  \n",
              "1    al  \n",
              "2    al  \n",
              "3    al  \n",
              "4    al  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsbZYJ9MzRBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##HAndle Categorical Features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjwb8KKLzRBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns=['region','type','laundry_options','parking_options','state']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nulN_CFrzRBt",
        "colab_type": "code",
        "colab": {},
        "outputId": "dd5a8e68-9b1b-4f65-db83-a07ed186c5e7"
      },
      "source": [
        "len(columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT_n1UpUzRB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def category_onehot_multcols(multcolumns):\n",
        "    df_final=final_df\n",
        "    i=0\n",
        "    for fields in multcolumns:\n",
        "        \n",
        "        print(fields)\n",
        "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
        "        \n",
        "        final_df.drop([fields],axis=1,inplace=True)\n",
        "        if i==0:\n",
        "            df_final=df1.copy()\n",
        "        else:\n",
        "            \n",
        "            df_final=pd.concat([df_final,df1],axis=1)\n",
        "        i=i+1\n",
        "       \n",
        "        \n",
        "    df_final=pd.concat([final_df,df_final],axis=1)\n",
        "        \n",
        "    return df_final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T85gLlqzzRCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_df=df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrL6iajNzRCW",
        "colab_type": "code",
        "colab": {},
        "outputId": "3c3f0687-9736-4235-f7ba-76efa7b17bfa"
      },
      "source": [
        "final_df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "region                     0\n",
              "price                      0\n",
              "type                       0\n",
              "sqfeet                     0\n",
              "beds                       0\n",
              "baths                      0\n",
              "cats_allowed               0\n",
              "dogs_allowed               0\n",
              "smoking_allowed            0\n",
              "wheelchair_access          0\n",
              "electric_vehicle_charge    0\n",
              "comes_furnished            0\n",
              "laundry_options            0\n",
              "parking_options            0\n",
              "lat                        0\n",
              "long                       0\n",
              "state                      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyUBRBzfzRCs",
        "colab_type": "code",
        "colab": {},
        "outputId": "4764d2ff-5c75-49a8-c4de-a024dc5d5b15"
      },
      "source": [
        "final_df['price']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         1195\n",
              "1         1120\n",
              "2          825\n",
              "3          800\n",
              "4          785\n",
              "          ... \n",
              "265185       0\n",
              "265186    1069\n",
              "265187    1507\n",
              "265188    1001\n",
              "265189    1164\n",
              "Name: price, Length: 265190, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8aed6-FzRC8",
        "colab_type": "code",
        "colab": {},
        "outputId": "c31988ea-e446-479d-f6c1-df3855c3993a"
      },
      "source": [
        "final_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(265190, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d_O6WePzRDL",
        "colab_type": "code",
        "colab": {},
        "outputId": "725292b0-0aa3-4337-a0fc-d8aac8e0e286"
      },
      "source": [
        "final_df=category_onehot_multcols(columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "region\n",
            "type\n",
            "laundry_options\n",
            "parking_options\n",
            "state\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg6LhjYMzRDd",
        "colab_type": "code",
        "colab": {},
        "outputId": "3b3ab48a-f024-4404-b01c-407197e913d7"
      },
      "source": [
        "final_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(265190, 367)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2lHPaOhzRDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_df =final_df.loc[:,~final_df.columns.duplicated()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AuJVk-TzRD8",
        "colab_type": "code",
        "colab": {},
        "outputId": "f8553f73-d823-43f2-9d44-697ee3887e04"
      },
      "source": [
        "final_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(265190, 367)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZlpTD4gzREI",
        "colab_type": "code",
        "colab": {},
        "outputId": "4f7d929b-f505-4276-ba8a-83756900aa3d"
      },
      "source": [
        "final_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>sqfeet</th>\n",
              "      <th>beds</th>\n",
              "      <th>baths</th>\n",
              "      <th>cats_allowed</th>\n",
              "      <th>dogs_allowed</th>\n",
              "      <th>smoking_allowed</th>\n",
              "      <th>wheelchair_access</th>\n",
              "      <th>electric_vehicle_charge</th>\n",
              "      <th>comes_furnished</th>\n",
              "      <th>...</th>\n",
              "      <th>nd</th>\n",
              "      <th>ne</th>\n",
              "      <th>nh</th>\n",
              "      <th>nj</th>\n",
              "      <th>nm</th>\n",
              "      <th>nv</th>\n",
              "      <th>ny</th>\n",
              "      <th>oh</th>\n",
              "      <th>ok</th>\n",
              "      <th>or</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1195</td>\n",
              "      <td>1908</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1120</td>\n",
              "      <td>1319</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>825</td>\n",
              "      <td>1133</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>800</td>\n",
              "      <td>927</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>785</td>\n",
              "      <td>1047</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265185</th>\n",
              "      <td>0</td>\n",
              "      <td>1061</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265186</th>\n",
              "      <td>1069</td>\n",
              "      <td>1020</td>\n",
              "      <td>2</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265187</th>\n",
              "      <td>1507</td>\n",
              "      <td>1660</td>\n",
              "      <td>2</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265188</th>\n",
              "      <td>1001</td>\n",
              "      <td>1220</td>\n",
              "      <td>3</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265189</th>\n",
              "      <td>1164</td>\n",
              "      <td>1300</td>\n",
              "      <td>2</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>265190 rows × 367 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        price  sqfeet  beds  baths  cats_allowed  dogs_allowed  \\\n",
              "0        1195    1908     3    2.0             1             1   \n",
              "1        1120    1319     3    2.0             1             1   \n",
              "2         825    1133     1    1.5             1             1   \n",
              "3         800     927     1    1.0             1             1   \n",
              "4         785    1047     2    1.0             1             1   \n",
              "...       ...     ...   ...    ...           ...           ...   \n",
              "265185      0    1061     2    2.0             1             1   \n",
              "265186   1069    1020     2    1.5             1             1   \n",
              "265187   1507    1660     2    1.5             1             1   \n",
              "265188   1001    1220     3    1.5             1             1   \n",
              "265189   1164    1300     2    2.5             1             1   \n",
              "\n",
              "        smoking_allowed  wheelchair_access  electric_vehicle_charge  \\\n",
              "0                     1                  0                        0   \n",
              "1                     1                  0                        0   \n",
              "2                     1                  0                        0   \n",
              "3                     1                  0                        0   \n",
              "4                     1                  0                        0   \n",
              "...                 ...                ...                      ...   \n",
              "265185                1                  0                        0   \n",
              "265186                1                  0                        0   \n",
              "265187                1                  0                        0   \n",
              "265188                1                  0                        0   \n",
              "265189                0                  0                        0   \n",
              "\n",
              "        comes_furnished  ...  nd  ne  nh  nj  nm  nv  ny  oh  ok  or  \n",
              "0                     0  ...   0   0   0   0   0   0   0   0   0   0  \n",
              "1                     0  ...   0   0   0   0   0   0   0   0   0   0  \n",
              "2                     0  ...   0   0   0   0   0   0   0   0   0   0  \n",
              "3                     0  ...   0   0   0   0   0   0   0   0   0   0  \n",
              "4                     0  ...   0   0   0   0   0   0   0   0   0   0  \n",
              "...                 ...  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  \n",
              "265185                0  ...   0   0   0   0   0   0   0   1   0   0  \n",
              "265186                0  ...   0   0   0   0   0   0   0   1   0   0  \n",
              "265187                0  ...   0   0   0   0   0   0   0   1   0   0  \n",
              "265188                0  ...   0   0   0   0   0   0   0   1   0   0  \n",
              "265189                0  ...   0   0   0   0   0   0   0   0   0   0  \n",
              "\n",
              "[265190 rows x 367 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDYDOaTrzREV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Train=final_df.iloc[:265180,:]\n",
        "df_Test=final_df.iloc[265180:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7okaYW3zREi",
        "colab_type": "code",
        "colab": {},
        "outputId": "37484a15-9749-4348-907d-ef724ea35102"
      },
      "source": [
        "df_Train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>sqfeet</th>\n",
              "      <th>beds</th>\n",
              "      <th>baths</th>\n",
              "      <th>cats_allowed</th>\n",
              "      <th>dogs_allowed</th>\n",
              "      <th>smoking_allowed</th>\n",
              "      <th>wheelchair_access</th>\n",
              "      <th>electric_vehicle_charge</th>\n",
              "      <th>comes_furnished</th>\n",
              "      <th>...</th>\n",
              "      <th>nd</th>\n",
              "      <th>ne</th>\n",
              "      <th>nh</th>\n",
              "      <th>nj</th>\n",
              "      <th>nm</th>\n",
              "      <th>nv</th>\n",
              "      <th>ny</th>\n",
              "      <th>oh</th>\n",
              "      <th>ok</th>\n",
              "      <th>or</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1195</td>\n",
              "      <td>1908</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1120</td>\n",
              "      <td>1319</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>825</td>\n",
              "      <td>1133</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>800</td>\n",
              "      <td>927</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>785</td>\n",
              "      <td>1047</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 367 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   price  sqfeet  beds  baths  cats_allowed  dogs_allowed  smoking_allowed  \\\n",
              "0   1195    1908     3    2.0             1             1                1   \n",
              "1   1120    1319     3    2.0             1             1                1   \n",
              "2    825    1133     1    1.5             1             1                1   \n",
              "3    800     927     1    1.0             1             1                1   \n",
              "4    785    1047     2    1.0             1             1                1   \n",
              "\n",
              "   wheelchair_access  electric_vehicle_charge  comes_furnished  ...  nd  ne  \\\n",
              "0                  0                        0                0  ...   0   0   \n",
              "1                  0                        0                0  ...   0   0   \n",
              "2                  0                        0                0  ...   0   0   \n",
              "3                  0                        0                0  ...   0   0   \n",
              "4                  0                        0                0  ...   0   0   \n",
              "\n",
              "   nh  nj  nm  nv  ny  oh  ok  or  \n",
              "0   0   0   0   0   0   0   0   0  \n",
              "1   0   0   0   0   0   0   0   0  \n",
              "2   0   0   0   0   0   0   0   0  \n",
              "3   0   0   0   0   0   0   0   0  \n",
              "4   0   0   0   0   0   0   0   0  \n",
              "\n",
              "[5 rows x 367 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3j-ixlBzREw",
        "colab_type": "code",
        "colab": {},
        "outputId": "cce9ea16-4859-45d0-b4ce-d5cb79e35b7b"
      },
      "source": [
        "df_Test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>sqfeet</th>\n",
              "      <th>beds</th>\n",
              "      <th>baths</th>\n",
              "      <th>cats_allowed</th>\n",
              "      <th>dogs_allowed</th>\n",
              "      <th>smoking_allowed</th>\n",
              "      <th>wheelchair_access</th>\n",
              "      <th>electric_vehicle_charge</th>\n",
              "      <th>comes_furnished</th>\n",
              "      <th>...</th>\n",
              "      <th>nd</th>\n",
              "      <th>ne</th>\n",
              "      <th>nh</th>\n",
              "      <th>nj</th>\n",
              "      <th>nm</th>\n",
              "      <th>nv</th>\n",
              "      <th>ny</th>\n",
              "      <th>oh</th>\n",
              "      <th>ok</th>\n",
              "      <th>or</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>265180</th>\n",
              "      <td>0</td>\n",
              "      <td>1053</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265181</th>\n",
              "      <td>1601</td>\n",
              "      <td>1222</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265182</th>\n",
              "      <td>1719</td>\n",
              "      <td>1630</td>\n",
              "      <td>3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265183</th>\n",
              "      <td>870</td>\n",
              "      <td>933</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265184</th>\n",
              "      <td>929</td>\n",
              "      <td>728</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 367 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        price  sqfeet  beds  baths  cats_allowed  dogs_allowed  \\\n",
              "265180      0    1053     2    2.0             1             1   \n",
              "265181   1601    1222     2    2.0             1             1   \n",
              "265182   1719    1630     3    2.5             1             1   \n",
              "265183    870     933     2    2.0             1             1   \n",
              "265184    929     728     1    1.0             1             1   \n",
              "\n",
              "        smoking_allowed  wheelchair_access  electric_vehicle_charge  \\\n",
              "265180                1                  0                        0   \n",
              "265181                1                  1                        0   \n",
              "265182                1                  1                        0   \n",
              "265183                1                  0                        0   \n",
              "265184                1                  1                        0   \n",
              "\n",
              "        comes_furnished  ...  nd  ne  nh  nj  nm  nv  ny  oh  ok  or  \n",
              "265180                0  ...   0   0   0   0   0   0   0   1   0   0  \n",
              "265181                0  ...   0   0   0   0   0   0   0   1   0   0  \n",
              "265182                0  ...   0   0   0   0   0   0   0   1   0   0  \n",
              "265183                0  ...   0   0   0   0   0   0   0   1   0   0  \n",
              "265184                0  ...   0   0   0   0   0   0   0   1   0   0  \n",
              "\n",
              "[5 rows x 367 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgcTnz58zRE_",
        "colab_type": "code",
        "colab": {},
        "outputId": "f0c1e4a9-1c6b-4aa3-9d55-a66a427f5783"
      },
      "source": [
        "df_Train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1422, 367)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgfC-LZozRFQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "22f3580f-a7ca-462c-dabf-4de55ce44d50"
      },
      "source": [
        "df_Test.drop(['price'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsDQkabDzRFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=df_Train.drop(['price'],axis=1)\n",
        "y_train=df_Train['price']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trkzbwKPzRFy",
        "colab_type": "text"
      },
      "source": [
        "## Prediciton and selecting the Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "656q7d-uzRF1",
        "colab_type": "code",
        "colab": {},
        "outputId": "70cad97a-1e0a-499d-b7b2-e3c45de91bb9"
      },
      "source": [
        "pip install scikit-learn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (0.22.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.18.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (0.14.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKYNl922zRGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "classifier=xgboost.XGBRegressor()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-EHCRfwzRGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost\n",
        "regressor=xgboost.XGBRegressor()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0KkW75zzRGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "booster=['gbtree','gblinear']\n",
        "base_score=[0.25,0.5,0.75,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NvTdkypzRHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Hyper Parameter Optimization\n",
        "\n",
        "\n",
        "n_estimators = [100, 500, 900, 1100, 1500]\n",
        "max_depth = [2, 3, 5, 10, 15]\n",
        "booster=['gbtree','gblinear']\n",
        "learning_rate=[0.05,0.1,0.15,0.20]\n",
        "min_child_weight=[1,2,3,4]\n",
        "\n",
        "# Define the grid of hyperparameters to search\n",
        "hyperparameter_grid = {\n",
        "    'n_estimators': n_estimators,\n",
        "    'max_depth':max_depth,\n",
        "    'learning_rate':learning_rate,\n",
        "    'min_child_weight':min_child_weight,\n",
        "    'booster':booster,\n",
        "    'base_score':base_score\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BzP8n-UzRHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up the random search with 4-fold cross validation\n",
        "random_cv = RandomizedSearchCV(estimator=regressor,\n",
        "            param_distributions=hyperparameter_grid,\n",
        "            cv=5, n_iter=50,\n",
        "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
        "            verbose = 5, \n",
        "            return_train_score = True,\n",
        "            random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywKucfu5zRHj",
        "colab_type": "code",
        "colab": {},
        "outputId": "9e51be59-4338-479b-efda-dd8a74f1e463"
      },
      "source": [
        "random_cv.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK15tJC3zRHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_cv.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm01ClIbzRH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_cv.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDQ5oSX0zRIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
        "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
        "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
        "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
        "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "       silent=True, subsample=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i9OPVnYzRIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regressor.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwcs9P9lzRId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "filename = 'finalized_model.pkl'\n",
        "pickle.dump(classifier, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSouIC4SzRIo",
        "colab_type": "code",
        "colab": {},
        "outputId": "0277130f-22d4-4a1b-f42d-208e5c4108ac"
      },
      "source": [
        "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  errors=errors)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrBY2E4WzRIz",
        "colab_type": "code",
        "colab": {},
        "outputId": "ef993319-07eb-4961-88b7-7ab08820edd1"
      },
      "source": [
        "df_Test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1459, 174)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et3UG4gjzRJV",
        "colab_type": "code",
        "colab": {},
        "outputId": "23561b0d-6f56-4fd0-afe7-bfc03e1c3f5c"
      },
      "source": [
        "df_Test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>...</th>\n",
              "      <th>Min2</th>\n",
              "      <th>Typ</th>\n",
              "      <th>Attchd</th>\n",
              "      <th>Basment</th>\n",
              "      <th>BuiltIn</th>\n",
              "      <th>CarPort</th>\n",
              "      <th>Detchd</th>\n",
              "      <th>RFn</th>\n",
              "      <th>P</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>896</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>468.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>121033.398438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1329</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>923.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>406.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>155717.390625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>928</td>\n",
              "      <td>701</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>791.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>185616.859375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>926</td>\n",
              "      <td>678</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>602.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>324.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>189161.546875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1280</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>263.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>175323.750000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 175 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
              "0       896         0          0             2       468.0       144.0   \n",
              "1      1329         0          0             3       923.0         0.0   \n",
              "2       928       701          0             3       791.0         0.0   \n",
              "3       926       678          0             3       602.0         0.0   \n",
              "4      1280         0          0             2       263.0         0.0   \n",
              "\n",
              "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch      ...        Min2  \\\n",
              "0           0.0           0.0      270.0              0      ...           0   \n",
              "1           0.0           0.0      406.0              0      ...           0   \n",
              "2           0.0           0.0      137.0              0      ...           0   \n",
              "3           0.0           0.0      324.0              0      ...           0   \n",
              "4           0.0           0.0     1017.0              0      ...           0   \n",
              "\n",
              "   Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P      SalePrice  \n",
              "0    1       1        0        0        0       0    0  0  121033.398438  \n",
              "1    1       1        0        0        0       0    0  0  155717.390625  \n",
              "2    1       1        0        0        0       0    0  0  185616.859375  \n",
              "3    1       1        0        0        0       0    0  0  189161.546875  \n",
              "4    1       1        0        0        0       0    1  0  175323.750000  \n",
              "\n",
              "[5 rows x 175 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 347
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GudkDOw_zRJp",
        "colab_type": "code",
        "colab": {},
        "outputId": "0018c109-0222-45c1-d9a3-7cca0caa18fe"
      },
      "source": [
        "df_Test.drop(['SalePrice'],axis=1).head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>...</th>\n",
              "      <th>Min1</th>\n",
              "      <th>Min2</th>\n",
              "      <th>Typ</th>\n",
              "      <th>Attchd</th>\n",
              "      <th>Basment</th>\n",
              "      <th>BuiltIn</th>\n",
              "      <th>CarPort</th>\n",
              "      <th>Detchd</th>\n",
              "      <th>RFn</th>\n",
              "      <th>P</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>896</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>468.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1329</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>923.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>406.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>928</td>\n",
              "      <td>701</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>791.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>926</td>\n",
              "      <td>678</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>602.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>324.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1280</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>263.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 174 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
              "0       896         0          0             2       468.0       144.0   \n",
              "1      1329         0          0             3       923.0         0.0   \n",
              "2       928       701          0             3       791.0         0.0   \n",
              "3       926       678          0             3       602.0         0.0   \n",
              "4      1280         0          0             2       263.0         0.0   \n",
              "\n",
              "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  Typ  \\\n",
              "0           0.0           0.0      270.0              0 ...     0     0    1   \n",
              "1           0.0           0.0      406.0              0 ...     0     0    1   \n",
              "2           0.0           0.0      137.0              0 ...     0     0    1   \n",
              "3           0.0           0.0      324.0              0 ...     0     0    1   \n",
              "4           0.0           0.0     1017.0              0 ...     0     0    1   \n",
              "\n",
              "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
              "0       1        0        0        0       0    0  0  \n",
              "1       1        0        0        0       0    0  0  \n",
              "2       1        0        0        0       0    0  0  \n",
              "3       1        0        0        0       0    0  0  \n",
              "4       1        0        0        0       0    1  0  \n",
              "\n",
              "[5 rows x 174 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 349
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWksjKJFzRJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=regressor.predict(df_Test.drop(['SalePrice'],axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HO_p6GqzRKE",
        "colab_type": "code",
        "colab": {},
        "outputId": "eab96256-6134-4c69-ef79-52de523c7ae7"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([119179.125, 158328.88 , 183704.81 , ..., 165757.22 , 118693.11 ,\n",
              "       230294.19 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3li-qGyAzRKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Create Sample Submission file and Submit using ANN\n",
        "pred=pd.DataFrame(ann_pred)\n",
        "sub_df=pd.read_csv('sample_submission.csv')\n",
        "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
        "datasets.columns=['Id','SalePrice']\n",
        "datasets.to_csv('sample_submission.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DldAxTMGzRK4",
        "colab_type": "text"
      },
      "source": [
        "## Step2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdVFGo0YzRK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred.columns=['SalePrice']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZHGCJJbzRLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_df=df_Train['SalePrice'].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frL0UqbTzRLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_df.column=['SalePrice']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oRq06BezRLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Train.drop(['SalePrice'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVnorhXFzRL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Train=pd.concat([df_Train,temp_df],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwQClmzxzRL8",
        "colab_type": "code",
        "colab": {},
        "outputId": "b1ff3570-31e5-4e64-bf5b-dee38797f1a4"
      },
      "source": [
        "df_Test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>...</th>\n",
              "      <th>Min2</th>\n",
              "      <th>Typ</th>\n",
              "      <th>Attchd</th>\n",
              "      <th>Basment</th>\n",
              "      <th>BuiltIn</th>\n",
              "      <th>CarPort</th>\n",
              "      <th>Detchd</th>\n",
              "      <th>RFn</th>\n",
              "      <th>P</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>896</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>468.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>121033.398438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1329</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>923.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>406.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>155717.390625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>928</td>\n",
              "      <td>701</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>791.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>185616.859375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>926</td>\n",
              "      <td>678</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>602.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>324.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>189161.546875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1280</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>263.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>175323.750000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 175 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
              "0       896         0          0             2       468.0       144.0   \n",
              "1      1329         0          0             3       923.0         0.0   \n",
              "2       928       701          0             3       791.0         0.0   \n",
              "3       926       678          0             3       602.0         0.0   \n",
              "4      1280         0          0             2       263.0         0.0   \n",
              "\n",
              "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch      ...        Min2  \\\n",
              "0           0.0           0.0      270.0              0      ...           0   \n",
              "1           0.0           0.0      406.0              0      ...           0   \n",
              "2           0.0           0.0      137.0              0      ...           0   \n",
              "3           0.0           0.0      324.0              0      ...           0   \n",
              "4           0.0           0.0     1017.0              0      ...           0   \n",
              "\n",
              "   Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P      SalePrice  \n",
              "0    1       1        0        0        0       0    0  0  121033.398438  \n",
              "1    1       1        0        0        0       0    0  0  155717.390625  \n",
              "2    1       1        0        0        0       0    0  0  185616.859375  \n",
              "3    1       1        0        0        0       0    0  0  189161.546875  \n",
              "4    1       1        0        0        0       0    1  0  175323.750000  \n",
              "\n",
              "[5 rows x 175 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5u1uJImzRMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Test=pd.concat([df_Test,pred],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arWbt536zRMP",
        "colab_type": "code",
        "colab": {},
        "outputId": "6321d50c-debb-4ed7-997d-c340441f24bc"
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 175)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJpif3p_zRMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Train=pd.concat([df_Train,df_Test],axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpIJOctpzRMd",
        "colab_type": "code",
        "colab": {},
        "outputId": "67eef0f2-1223-4895-dad4-b8c9252219cd"
      },
      "source": [
        "df_Train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2881, 175)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 343
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84l8OGtOzRMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
        "y_train=df_Train['SalePrice']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lAH9oopzRMt",
        "colab_type": "text"
      },
      "source": [
        "## Artificial Neural Network Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVq_xpTZzRMw",
        "colab_type": "code",
        "colab": {},
        "outputId": "91970b0e-1bb5-4f88-aae3-5b20f6f47de4"
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LeakyReLU,PReLU,ELU\n",
        "from keras.layers import Dropout\n",
        "\n",
        "\n",
        "# Initialising the ANN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 174))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n",
        "\n",
        "# Adding the third hidden layer\n",
        "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(output_dim = 1, init = 'he_uniform'))\n",
        "\n",
        "# Compiling the ANN\n",
        "classifier.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "model_history=classifier.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
            "  del sys.path[0]\n",
            "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
            "  app.launch_new_instance()\n",
            "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
            "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
            "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 2304 samples, validate on 577 samples\n",
            "Epoch 1/1000\n",
            "2304/2304 [==============================] - 2s 1ms/step - loss: 113530.5093 - val_loss: 56624.8765\n",
            "Epoch 2/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 62615.1298 - val_loss: 50444.1900\n",
            "Epoch 3/1000\n",
            "2304/2304 [==============================] - 1s 464us/step - loss: 56279.5739 - val_loss: 44504.8296\n",
            "Epoch 4/1000\n",
            "2304/2304 [==============================] - 1s 455us/step - loss: 50261.0310 - val_loss: 39335.5723\n",
            "Epoch 5/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 44449.5163 - val_loss: 35396.5539\n",
            "Epoch 6/1000\n",
            "2304/2304 [==============================] - 1s 461us/step - loss: 40090.4315 - val_loss: 35178.2237\n",
            "Epoch 7/1000\n",
            "2304/2304 [==============================] - 1s 461us/step - loss: 37493.4126 - val_loss: 31983.3301\n",
            "Epoch 8/1000\n",
            "2304/2304 [==============================] - 1s 433us/step - loss: 36462.1401 - val_loss: 34241.1639\n",
            "Epoch 9/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 35635.4539 - val_loss: 32087.6040\n",
            "Epoch 10/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 35851.5885 - val_loss: 32125.1113\n",
            "Epoch 11/1000\n",
            "2304/2304 [==============================] - 1s 463us/step - loss: 35622.6530 - val_loss: 31914.6602\n",
            "Epoch 12/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 35187.7144 - val_loss: 31882.3983\n",
            "Epoch 13/1000\n",
            "2304/2304 [==============================] - 1s 427us/step - loss: 35196.1213 - val_loss: 32342.4395\n",
            "Epoch 14/1000\n",
            "2304/2304 [==============================] - 1s 424us/step - loss: 34929.6660 - val_loss: 31565.0875\n",
            "Epoch 15/1000\n",
            "2304/2304 [==============================] - 1s 429us/step - loss: 34672.9052 - val_loss: 32177.3833\n",
            "Epoch 16/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 34501.2563 - val_loss: 31293.5959\n",
            "Epoch 17/1000\n",
            "2304/2304 [==============================] - 1s 459us/step - loss: 34804.2316 - val_loss: 31182.3204\n",
            "Epoch 18/1000\n",
            "2304/2304 [==============================] - 2s 778us/step - loss: 34455.4584 - val_loss: 31376.9020\n",
            "Epoch 19/1000\n",
            "2304/2304 [==============================] - 1s 467us/step - loss: 34377.8071 - val_loss: 31301.4047\n",
            "Epoch 20/1000\n",
            "2304/2304 [==============================] - 1s 477us/step - loss: 34164.2543 - val_loss: 31142.9020\n",
            "Epoch 21/1000\n",
            "2304/2304 [==============================] - 1s 469us/step - loss: 34009.0316 - val_loss: 31243.3016\n",
            "Epoch 22/1000\n",
            "2304/2304 [==============================] - 1s 422us/step - loss: 33660.4401 - val_loss: 31494.8445\n",
            "Epoch 23/1000\n",
            "2304/2304 [==============================] - 1s 413us/step - loss: 33812.4372 - val_loss: 31299.1932\n",
            "Epoch 24/1000\n",
            "2304/2304 [==============================] - 1s 419us/step - loss: 33589.9288 - val_loss: 31848.2731\n",
            "Epoch 25/1000\n",
            "2304/2304 [==============================] - 1s 432us/step - loss: 33607.1809 - val_loss: 30390.6748\n",
            "Epoch 26/1000\n",
            "2304/2304 [==============================] - 1s 426us/step - loss: 33473.9579 - val_loss: 30910.1593\n",
            "Epoch 27/1000\n",
            "2304/2304 [==============================] - 1s 433us/step - loss: 33236.2349 - val_loss: 30219.5441\n",
            "Epoch 28/1000\n",
            "2304/2304 [==============================] - 1s 420us/step - loss: 33243.2710 - val_loss: 30179.0993\n",
            "Epoch 29/1000\n",
            "2304/2304 [==============================] - 1s 430us/step - loss: 32929.2295 - val_loss: 30128.3545\n",
            "Epoch 30/1000\n",
            "2304/2304 [==============================] - 1s 420us/step - loss: 32963.0511 - val_loss: 30510.0357\n",
            "Epoch 31/1000\n",
            "2304/2304 [==============================] - 1s 418us/step - loss: 32787.1626 - val_loss: 29853.5188\n",
            "Epoch 32/1000\n",
            "2304/2304 [==============================] - 1s 427us/step - loss: 32766.8486 - val_loss: 30704.6890\n",
            "Epoch 33/1000\n",
            "2304/2304 [==============================] - 1s 425us/step - loss: 32790.5330 - val_loss: 30381.5674\n",
            "Epoch 34/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 32740.6885 - val_loss: 29614.6660\n",
            "Epoch 35/1000\n",
            "2304/2304 [==============================] - 1s 420us/step - loss: 32658.3221 - val_loss: 30323.1913\n",
            "Epoch 36/1000\n",
            "2304/2304 [==============================] - 1s 416us/step - loss: 32570.0888 - val_loss: 30407.4534\n",
            "Epoch 37/1000\n",
            "2304/2304 [==============================] - 1s 423us/step - loss: 32189.7531 - val_loss: 30379.3509\n",
            "Epoch 38/1000\n",
            "2304/2304 [==============================] - 1s 432us/step - loss: 32140.4911 - val_loss: 29347.5356\n",
            "Epoch 39/1000\n",
            "2304/2304 [==============================] - 1s 427us/step - loss: 31913.3835 - val_loss: 29861.8741\n",
            "Epoch 40/1000\n",
            "2304/2304 [==============================] - 1s 421us/step - loss: 32135.0634 - val_loss: 29108.2475\n",
            "Epoch 41/1000\n",
            "2304/2304 [==============================] - 1s 423us/step - loss: 32026.9856 - val_loss: 29142.3169\n",
            "Epoch 42/1000\n",
            "2304/2304 [==============================] - 1s 425us/step - loss: 31792.7488 - val_loss: 29323.2182\n",
            "Epoch 43/1000\n",
            "2304/2304 [==============================] - 1s 422us/step - loss: 31622.7127 - val_loss: 29028.4757\n",
            "Epoch 44/1000\n",
            "2304/2304 [==============================] - 1s 426us/step - loss: 31769.7568 - val_loss: 29493.1864\n",
            "Epoch 45/1000\n",
            "2304/2304 [==============================] - 1s 433us/step - loss: 31732.7656 - val_loss: 29812.4935\n",
            "Epoch 46/1000\n",
            "2304/2304 [==============================] - 1s 416us/step - loss: 31434.8387 - val_loss: 28903.6488\n",
            "Epoch 47/1000\n",
            "2304/2304 [==============================] - 1s 414us/step - loss: 31234.3539 - val_loss: 28895.0965\n",
            "Epoch 48/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 31151.4855 - val_loss: 28861.3638\n",
            "Epoch 49/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 31274.5573 - val_loss: 29427.3137\n",
            "Epoch 50/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 31510.8220 - val_loss: 28567.3384\n",
            "Epoch 51/1000\n",
            "2304/2304 [==============================] - 1s 423us/step - loss: 31460.1977 - val_loss: 28814.4977\n",
            "Epoch 52/1000\n",
            "2304/2304 [==============================] - 1s 415us/step - loss: 31085.8429 - val_loss: 28524.2395\n",
            "Epoch 53/1000\n",
            "2304/2304 [==============================] - 1s 426us/step - loss: 30989.9977 - val_loss: 28568.5788\n",
            "Epoch 54/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 31092.4584 - val_loss: 28378.7455\n",
            "Epoch 55/1000\n",
            "2304/2304 [==============================] - 1s 433us/step - loss: 30932.9268 - val_loss: 30094.5473\n",
            "Epoch 56/1000\n",
            "2304/2304 [==============================] - 1s 430us/step - loss: 30684.4676 - val_loss: 28414.4087\n",
            "Epoch 57/1000\n",
            "2304/2304 [==============================] - 1s 422us/step - loss: 30493.6564 - val_loss: 29508.0253\n",
            "Epoch 58/1000\n",
            "2304/2304 [==============================] - 1s 429us/step - loss: 30652.6024 - val_loss: 28326.5143\n",
            "Epoch 59/1000\n",
            "2304/2304 [==============================] - 1s 426us/step - loss: 30778.1669 - val_loss: 28056.4234\n",
            "Epoch 60/1000\n",
            "2304/2304 [==============================] - 1s 424us/step - loss: 30424.7307 - val_loss: 28010.0378\n",
            "Epoch 61/1000\n",
            "2304/2304 [==============================] - 1s 425us/step - loss: 30072.8579 - val_loss: 28027.6187\n",
            "Epoch 62/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 30334.3219 - val_loss: 28459.9857\n",
            "Epoch 63/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 30427.8750 - val_loss: 29863.5684\n",
            "Epoch 64/1000\n",
            "2304/2304 [==============================] - 1s 430us/step - loss: 30285.2018 - val_loss: 28957.1549\n",
            "Epoch 65/1000\n",
            "2304/2304 [==============================] - 1s 417us/step - loss: 30310.4877 - val_loss: 28183.0357\n",
            "Epoch 66/1000\n",
            "2304/2304 [==============================] - 1s 405us/step - loss: 30276.2501 - val_loss: 27665.3018\n",
            "Epoch 67/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 29832.1718 - val_loss: 27712.5372\n",
            "Epoch 68/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 30272.4041 - val_loss: 27718.7824\n",
            "Epoch 69/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 30113.7119 - val_loss: 28000.3839\n",
            "Epoch 70/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 29942.6214 - val_loss: 27786.2428\n",
            "Epoch 71/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 29859.0674 - val_loss: 27215.5401\n",
            "Epoch 72/1000\n",
            "2304/2304 [==============================] - 1s 471us/step - loss: 29209.5491 - val_loss: 27173.5760\n",
            "Epoch 73/1000\n",
            "2304/2304 [==============================] - 1s 457us/step - loss: 29919.4843 - val_loss: 27220.3691\n",
            "Epoch 74/1000\n",
            "2304/2304 [==============================] - 1s 450us/step - loss: 29509.6134 - val_loss: 27340.0882\n",
            "Epoch 75/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 29708.4845 - val_loss: 27312.6990\n",
            "Epoch 76/1000\n",
            "2304/2304 [==============================] - 1s 473us/step - loss: 29519.9725 - val_loss: 27508.6494\n",
            "Epoch 77/1000\n",
            "2304/2304 [==============================] - 1s 471us/step - loss: 29357.4566 - val_loss: 26867.6287\n",
            "Epoch 78/1000\n",
            "2304/2304 [==============================] - 1s 461us/step - loss: 29159.6736 - val_loss: 26893.8640\n",
            "Epoch 79/1000\n",
            "2304/2304 [==============================] - 1s 452us/step - loss: 29366.9112 - val_loss: 26603.1912\n",
            "Epoch 80/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 29120.4931 - val_loss: 26661.9235\n",
            "Epoch 81/1000\n",
            "2304/2304 [==============================] - 1s 466us/step - loss: 28946.7935 - val_loss: 27871.8099\n",
            "Epoch 82/1000\n",
            "2304/2304 [==============================] - 1s 453us/step - loss: 29138.3855 - val_loss: 26531.3914\n",
            "Epoch 83/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 28846.1910 - val_loss: 28481.5947\n",
            "Epoch 84/1000\n",
            "2304/2304 [==============================] - 1s 461us/step - loss: 29017.1691 - val_loss: 26508.0993\n",
            "Epoch 85/1000\n",
            "2304/2304 [==============================] - 1s 458us/step - loss: 28775.6919 - val_loss: 26779.5843\n",
            "Epoch 86/1000\n",
            "2304/2304 [==============================] - 1s 459us/step - loss: 29089.2547 - val_loss: 27172.3217\n",
            "Epoch 87/1000\n",
            "2304/2304 [==============================] - 1s 471us/step - loss: 28686.1871 - val_loss: 26091.4350\n",
            "Epoch 88/1000\n",
            "2304/2304 [==============================] - 1s 461us/step - loss: 28698.4660 - val_loss: 26102.4028\n",
            "Epoch 89/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 28699.3697 - val_loss: 26289.4353\n",
            "Epoch 90/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 28489.5871 - val_loss: 27897.5505\n",
            "Epoch 91/1000\n",
            "2304/2304 [==============================] - 1s 467us/step - loss: 28665.1914 - val_loss: 25854.9589\n",
            "Epoch 92/1000\n",
            "2304/2304 [==============================] - 1s 465us/step - loss: 28285.7090 - val_loss: 25977.9663\n",
            "Epoch 93/1000\n",
            "2304/2304 [==============================] - 1s 462us/step - loss: 28285.7983 - val_loss: 25438.4628\n",
            "Epoch 94/1000\n",
            "2304/2304 [==============================] - 1s 461us/step - loss: 28321.3720 - val_loss: 25585.6818\n",
            "Epoch 95/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 28190.3902 - val_loss: 25334.2817\n",
            "Epoch 96/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 28360.6425 - val_loss: 25095.3392\n",
            "Epoch 97/1000\n",
            "2304/2304 [==============================] - 1s 468us/step - loss: 28196.4608 - val_loss: 24977.6499\n",
            "Epoch 98/1000\n",
            "2304/2304 [==============================] - 1s 460us/step - loss: 28143.1103 - val_loss: 24957.5144\n",
            "Epoch 99/1000\n",
            "2304/2304 [==============================] - ETA: 0s - loss: 28541.725 - 1s 465us/step - loss: 28404.1788 - val_loss: 25377.6330\n",
            "Epoch 100/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 27923.1122 - val_loss: 25035.9833\n",
            "Epoch 101/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 28224.6294 - val_loss: 24864.9644\n",
            "Epoch 102/1000\n",
            "2304/2304 [==============================] - 1s 450us/step - loss: 27838.1132 - val_loss: 26435.8536\n",
            "Epoch 103/1000\n",
            "2304/2304 [==============================] - 1s 457us/step - loss: 27936.2079 - val_loss: 24885.9012\n",
            "Epoch 104/1000\n",
            "2304/2304 [==============================] - ETA: 0s - loss: 27583.212 - 1s 450us/step - loss: 27619.0787 - val_loss: 24613.4044\n",
            "Epoch 105/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 27628.1560 - val_loss: 24228.4823\n",
            "Epoch 106/1000\n",
            "2304/2304 [==============================] - 1s 463us/step - loss: 27878.6943 - val_loss: 24845.3175\n",
            "Epoch 107/1000\n",
            "2304/2304 [==============================] - 1s 465us/step - loss: 27493.7438 - val_loss: 24612.2324\n",
            "Epoch 108/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 27134.2120 - val_loss: 25914.3079\n",
            "Epoch 109/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 27448.0619 - val_loss: 23640.7174\n",
            "Epoch 110/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 27225.6602 - val_loss: 24300.4790\n",
            "Epoch 111/1000\n",
            "2304/2304 [==============================] - 1s 452us/step - loss: 27457.5783 - val_loss: 23591.0836\n",
            "Epoch 112/1000\n",
            "2304/2304 [==============================] - 1s 450us/step - loss: 27562.5854 - val_loss: 23601.4916\n",
            "Epoch 113/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 26970.8130 - val_loss: 23496.5879\n",
            "Epoch 114/1000\n",
            "2304/2304 [==============================] - 1s 456us/step - loss: 27141.8372 - val_loss: 24716.6597\n",
            "Epoch 115/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 26687.5030 - val_loss: 25936.5065\n",
            "Epoch 116/1000\n",
            "2304/2304 [==============================] - 1s 458us/step - loss: 26811.0217 - val_loss: 23067.7963\n",
            "Epoch 117/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 26862.9685 - val_loss: 23789.6916\n",
            "Epoch 118/1000\n",
            "2304/2304 [==============================] - 1s 459us/step - loss: 26478.2679 - val_loss: 24595.6749\n",
            "Epoch 119/1000\n",
            "2304/2304 [==============================] - 1s 464us/step - loss: 26766.5188 - val_loss: 23377.8840\n",
            "Epoch 120/1000\n",
            "2304/2304 [==============================] - 1s 461us/step - loss: 26545.6570 - val_loss: 22453.2940\n",
            "Epoch 121/1000\n",
            "2304/2304 [==============================] - 1s 467us/step - loss: 26442.3213 - val_loss: 22567.1628\n",
            "Epoch 122/1000\n",
            "2304/2304 [==============================] - 1s 465us/step - loss: 26011.6722 - val_loss: 24087.4123\n",
            "Epoch 123/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 26506.6031 - val_loss: 22453.8540\n",
            "Epoch 124/1000\n",
            "2304/2304 [==============================] - 1s 454us/step - loss: 26042.1024 - val_loss: 22348.5490\n",
            "Epoch 125/1000\n",
            "2304/2304 [==============================] - 1s 466us/step - loss: 26685.7815 - val_loss: 21968.0753\n",
            "Epoch 126/1000\n",
            "2304/2304 [==============================] - 1s 454us/step - loss: 25654.7254 - val_loss: 22398.2175\n",
            "Epoch 127/1000\n",
            "2304/2304 [==============================] - 1s 468us/step - loss: 25909.7507 - val_loss: 21961.1548\n",
            "Epoch 128/1000\n",
            "2304/2304 [==============================] - 1s 480us/step - loss: 25938.8809 - val_loss: 21437.6150\n",
            "Epoch 129/1000\n",
            "2304/2304 [==============================] - 1s 476us/step - loss: 25268.5747 - val_loss: 21907.7049\n",
            "Epoch 130/1000\n",
            "2304/2304 [==============================] - 1s 470us/step - loss: 25609.2470 - val_loss: 21246.5780\n",
            "Epoch 131/1000\n",
            "2304/2304 [==============================] - 1s 465us/step - loss: 25023.4624 - val_loss: 24637.6923\n",
            "Epoch 132/1000\n",
            "2304/2304 [==============================] - 1s 520us/step - loss: 25366.8912 - val_loss: 21211.1705\n",
            "Epoch 133/1000\n",
            "2304/2304 [==============================] - 1s 479us/step - loss: 25424.9557 - val_loss: 21021.8191\n",
            "Epoch 134/1000\n",
            "2304/2304 [==============================] - 1s 464us/step - loss: 25343.5929 - val_loss: 21586.6650\n",
            "Epoch 135/1000\n",
            "2304/2304 [==============================] - 1s 462us/step - loss: 24995.2175 - val_loss: 21105.6569\n",
            "Epoch 136/1000\n",
            "2304/2304 [==============================] - 1s 465us/step - loss: 24986.7363 - val_loss: 20605.5033\n",
            "Epoch 137/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 25225.4030 - val_loss: 20552.5941\n",
            "Epoch 138/1000\n",
            "2304/2304 [==============================] - 1s 452us/step - loss: 25014.9195 - val_loss: 21813.1205\n",
            "Epoch 139/1000\n",
            "2304/2304 [==============================] - 1s 452us/step - loss: 24983.0982 - val_loss: 20684.3204\n",
            "Epoch 140/1000\n",
            "2304/2304 [==============================] - 1s 464us/step - loss: 24864.2334 - val_loss: 20245.8430\n",
            "Epoch 141/1000\n",
            "2304/2304 [==============================] - 1s 466us/step - loss: 24915.6213 - val_loss: 19954.3808\n",
            "Epoch 142/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 24832.0423 - val_loss: 22799.6597\n",
            "Epoch 143/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 24758.2035 - val_loss: 20148.5544\n",
            "Epoch 144/1000\n",
            "2304/2304 [==============================] - 1s 461us/step - loss: 24726.4656 - val_loss: 19816.7254\n",
            "Epoch 145/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 24342.4105 - val_loss: 21506.8392\n",
            "Epoch 146/1000\n",
            "2304/2304 [==============================] - 1s 494us/step - loss: 24704.4509 - val_loss: 19672.9874\n",
            "Epoch 147/1000\n",
            "2304/2304 [==============================] - 1s 483us/step - loss: 24873.8309 - val_loss: 19765.3019\n",
            "Epoch 148/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 24126.7666 - val_loss: 21504.0878\n",
            "Epoch 149/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 24424.1095 - val_loss: 21462.0763\n",
            "Epoch 150/1000\n",
            "2304/2304 [==============================] - 1s 450us/step - loss: 24470.7238 - val_loss: 19617.8413\n",
            "Epoch 151/1000\n",
            "2304/2304 [==============================] - 1s 468us/step - loss: 24235.2767 - val_loss: 20478.6877\n",
            "Epoch 152/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 23886.3026 - val_loss: 19679.8546\n",
            "Epoch 153/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 24203.4083 - val_loss: 19225.7126\n",
            "Epoch 154/1000\n",
            "2304/2304 [==============================] - 1s 459us/step - loss: 24125.6937 - val_loss: 18712.8627\n",
            "Epoch 155/1000\n",
            "2304/2304 [==============================] - 1s 457us/step - loss: 23699.3783 - val_loss: 19005.6716\n",
            "Epoch 156/1000\n",
            "2304/2304 [==============================] - 1s 464us/step - loss: 23628.8058 - val_loss: 20574.2034\n",
            "Epoch 157/1000\n",
            "2304/2304 [==============================] - 1s 466us/step - loss: 23527.5995 - val_loss: 20440.9397\n",
            "Epoch 158/1000\n",
            "2304/2304 [==============================] - 1s 462us/step - loss: 23367.5987 - val_loss: 20027.8654\n",
            "Epoch 159/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 23393.3923 - val_loss: 18406.9154\n",
            "Epoch 160/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 23547.7516 - val_loss: 19510.1907\n",
            "Epoch 161/1000\n",
            "2304/2304 [==============================] - 1s 455us/step - loss: 23700.4968 - val_loss: 19711.2351\n",
            "Epoch 162/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 23521.9805 - val_loss: 19353.0765\n",
            "Epoch 163/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 23289.4974 - val_loss: 18495.0024\n",
            "Epoch 164/1000\n",
            "2304/2304 [==============================] - 1s 467us/step - loss: 23146.1177 - val_loss: 18525.8958\n",
            "Epoch 165/1000\n",
            "2304/2304 [==============================] - 1s 474us/step - loss: 23378.2289 - val_loss: 18674.6753\n",
            "Epoch 166/1000\n",
            "2304/2304 [==============================] - 1s 432us/step - loss: 22990.6150 - val_loss: 18405.3405\n",
            "Epoch 167/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 23208.1085 - val_loss: 18444.8079\n",
            "Epoch 168/1000\n",
            "2304/2304 [==============================] - 1s 464us/step - loss: 23341.9950 - val_loss: 18214.6930\n",
            "Epoch 169/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 22968.4293 - val_loss: 18287.0789\n",
            "Epoch 170/1000\n",
            "2304/2304 [==============================] - 1s 453us/step - loss: 23336.9285 - val_loss: 19328.6353\n",
            "Epoch 171/1000\n",
            "2304/2304 [==============================] - 1s 455us/step - loss: 23004.5811 - val_loss: 22645.0320\n",
            "Epoch 172/1000\n",
            "2304/2304 [==============================] - 1s 460us/step - loss: 23450.7607 - val_loss: 18237.4190\n",
            "Epoch 173/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 23322.7922 - val_loss: 18528.1455\n",
            "Epoch 174/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 22646.3451 - val_loss: 18115.4026\n",
            "Epoch 175/1000\n",
            "2304/2304 [==============================] - 1s 453us/step - loss: 22568.9873 - val_loss: 19539.2561\n",
            "Epoch 176/1000\n",
            "2304/2304 [==============================] - 1s 459us/step - loss: 23544.2008 - val_loss: 17933.2717\n",
            "Epoch 177/1000\n",
            "2304/2304 [==============================] - 1s 458us/step - loss: 22497.0116 - val_loss: 17354.5006\n",
            "Epoch 178/1000\n",
            "2304/2304 [==============================] - 1s 458us/step - loss: 22879.9811 - val_loss: 17579.1927\n",
            "Epoch 179/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 22938.6665 - val_loss: 18413.8741\n",
            "Epoch 180/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 22665.2603 - val_loss: 19428.7250\n",
            "Epoch 181/1000\n",
            "2304/2304 [==============================] - 1s 461us/step - loss: 22319.2484 - val_loss: 17366.1969\n",
            "Epoch 182/1000\n",
            "2304/2304 [==============================] - 1s 453us/step - loss: 22669.5232 - val_loss: 18838.8342\n",
            "Epoch 183/1000\n",
            "2304/2304 [==============================] - 1s 452us/step - loss: 22451.1597 - val_loss: 18472.8874\n",
            "Epoch 184/1000\n",
            "2304/2304 [==============================] - 1s 461us/step - loss: 22706.7617 - val_loss: 18255.4424\n",
            "Epoch 185/1000\n",
            "2304/2304 [==============================] - 1s 463us/step - loss: 22957.0078 - val_loss: 17473.3416\n",
            "Epoch 186/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 22531.9464 - val_loss: 16844.6493\n",
            "Epoch 187/1000\n",
            "2304/2304 [==============================] - 1s 474us/step - loss: 22240.5742 - val_loss: 17564.5887\n",
            "Epoch 188/1000\n",
            "2304/2304 [==============================] - 1s 471us/step - loss: 22642.6283 - val_loss: 17112.6908\n",
            "Epoch 189/1000\n",
            "2304/2304 [==============================] - 1s 462us/step - loss: 22320.6819 - val_loss: 17639.8543\n",
            "Epoch 190/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 22117.3255 - val_loss: 17005.3269\n",
            "Epoch 191/1000\n",
            "2304/2304 [==============================] - 1s 463us/step - loss: 22249.5553 - val_loss: 18395.3013\n",
            "Epoch 192/1000\n",
            "2304/2304 [==============================] - 1s 456us/step - loss: 22401.0267 - val_loss: 16680.4410\n",
            "Epoch 193/1000\n",
            "2304/2304 [==============================] - 1s 466us/step - loss: 22384.8159 - val_loss: 17162.2615\n",
            "Epoch 194/1000\n",
            "2304/2304 [==============================] - 1s 475us/step - loss: 21983.3552 - val_loss: 18605.2577\n",
            "Epoch 195/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 22257.2526 - val_loss: 17034.5954\n",
            "Epoch 196/1000\n",
            "2304/2304 [==============================] - 1s 465us/step - loss: 22122.9456 - val_loss: 17328.9022\n",
            "Epoch 197/1000\n",
            "2304/2304 [==============================] - 1s 471us/step - loss: 22467.4348 - val_loss: 17312.1251\n",
            "Epoch 198/1000\n",
            "2304/2304 [==============================] - 1s 480us/step - loss: 22034.0424 - val_loss: 16346.6881\n",
            "Epoch 199/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 21772.8173 - val_loss: 16449.1762\n",
            "Epoch 200/1000\n",
            "2304/2304 [==============================] - 1s 466us/step - loss: 21616.0995 - val_loss: 19556.2224\n",
            "Epoch 201/1000\n",
            "2304/2304 [==============================] - 1s 464us/step - loss: 22326.2749 - val_loss: 16196.6720\n",
            "Epoch 202/1000\n",
            "2304/2304 [==============================] - 1s 452us/step - loss: 22678.2432 - val_loss: 16400.9500\n",
            "Epoch 203/1000\n",
            "2304/2304 [==============================] - 1s 462us/step - loss: 21954.1421 - val_loss: 17115.8815\n",
            "Epoch 204/1000\n",
            "2304/2304 [==============================] - 1s 455us/step - loss: 21574.3031 - val_loss: 16127.1571\n",
            "Epoch 205/1000\n",
            "2304/2304 [==============================] - 1s 480us/step - loss: 22338.9508 - val_loss: 19444.3208\n",
            "Epoch 206/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 21852.7934 - val_loss: 19308.3233\n",
            "Epoch 207/1000\n",
            "2304/2304 [==============================] - 1s 473us/step - loss: 21872.5774 - val_loss: 17685.5849\n",
            "Epoch 208/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 21486.7361 - val_loss: 16639.5072\n",
            "Epoch 209/1000\n",
            "2304/2304 [==============================] - 1s 464us/step - loss: 21571.2908 - val_loss: 16761.9651\n",
            "Epoch 210/1000\n",
            "2304/2304 [==============================] - 1s 461us/step - loss: 21631.3609 - val_loss: 15658.4923\n",
            "Epoch 211/1000\n",
            "2304/2304 [==============================] - 1s 464us/step - loss: 21486.4054 - val_loss: 15814.1505\n",
            "Epoch 212/1000\n",
            "2304/2304 [==============================] - 1s 455us/step - loss: 21541.5087 - val_loss: 17495.6494\n",
            "Epoch 213/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 22039.3132 - val_loss: 18907.8804\n",
            "Epoch 214/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 21535.5008 - val_loss: 16334.5270\n",
            "Epoch 215/1000\n",
            "2304/2304 [==============================] - 1s 474us/step - loss: 21397.5464 - val_loss: 15527.8804\n",
            "Epoch 216/1000\n",
            "2304/2304 [==============================] - 1s 459us/step - loss: 20970.6127 - val_loss: 15893.2644\n",
            "Epoch 217/1000\n",
            "2304/2304 [==============================] - 1s 454us/step - loss: 21382.1890 - val_loss: 16356.3695\n",
            "Epoch 218/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 21161.6115 - val_loss: 17358.3467\n",
            "Epoch 219/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 21313.9134 - val_loss: 16149.4819\n",
            "Epoch 220/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 21500.9419 - val_loss: 15796.3191\n",
            "Epoch 221/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 21536.2349 - val_loss: 15471.1339\n",
            "Epoch 222/1000\n",
            "2304/2304 [==============================] - 1s 463us/step - loss: 21088.8941 - val_loss: 15343.0244\n",
            "Epoch 223/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 21667.5794 - val_loss: 17580.5199\n",
            "Epoch 224/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 20965.1858 - val_loss: 15803.6322\n",
            "Epoch 225/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 21442.6807 - val_loss: 17598.5028\n",
            "Epoch 226/1000\n",
            "2304/2304 [==============================] - 1s 471us/step - loss: 21107.7338 - val_loss: 15927.4279\n",
            "Epoch 227/1000\n",
            "2304/2304 [==============================] - 1s 459us/step - loss: 20982.8748 - val_loss: 16270.2747\n",
            "Epoch 228/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 21420.9400 - val_loss: 15423.4538\n",
            "Epoch 229/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 20855.8819 - val_loss: 16644.8780\n",
            "Epoch 230/1000\n",
            "2304/2304 [==============================] - 1s 458us/step - loss: 20768.6303 - val_loss: 15575.5588\n",
            "Epoch 231/1000\n",
            "2304/2304 [==============================] - 1s 455us/step - loss: 21261.2271 - val_loss: 16437.3966\n",
            "Epoch 232/1000\n",
            "2304/2304 [==============================] - 1s 457us/step - loss: 21497.1832 - val_loss: 15420.6945\n",
            "Epoch 233/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 20544.3840 - val_loss: 15224.6794\n",
            "Epoch 234/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 21233.0104 - val_loss: 15038.2329\n",
            "Epoch 235/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 21491.5446 - val_loss: 17434.5473\n",
            "Epoch 236/1000\n",
            "2304/2304 [==============================] - 1s 454us/step - loss: 21326.1712 - val_loss: 16683.8884\n",
            "Epoch 237/1000\n",
            "2304/2304 [==============================] - 1s 450us/step - loss: 21116.4700 - val_loss: 15612.9380\n",
            "Epoch 238/1000\n",
            "2304/2304 [==============================] - 1s 463us/step - loss: 22033.4280 - val_loss: 15167.3380\n",
            "Epoch 239/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 21327.5555 - val_loss: 15373.3279\n",
            "Epoch 240/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 20829.2319 - val_loss: 15861.8656\n",
            "Epoch 241/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 20925.8254 - val_loss: 15428.4299\n",
            "Epoch 242/1000\n",
            "2304/2304 [==============================] - 1s 510us/step - loss: 21137.2842 - val_loss: 19346.3964\n",
            "Epoch 243/1000\n",
            "2304/2304 [==============================] - 1s 495us/step - loss: 20912.4358 - val_loss: 15086.4801\n",
            "Epoch 244/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 20783.2399 - val_loss: 17047.4020\n",
            "Epoch 245/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 20600.0964 - val_loss: 16235.3380\n",
            "Epoch 246/1000\n",
            "2304/2304 [==============================] - 1s 459us/step - loss: 20756.1085 - val_loss: 15630.0819\n",
            "Epoch 247/1000\n",
            "2304/2304 [==============================] - 1s 487us/step - loss: 20794.2793 - val_loss: 15813.6791\n",
            "Epoch 248/1000\n",
            "2304/2304 [==============================] - 1s 463us/step - loss: 20578.2091 - val_loss: 14941.2435\n",
            "Epoch 249/1000\n",
            "2304/2304 [==============================] - 1s 459us/step - loss: 20526.0308 - val_loss: 17806.7003\n",
            "Epoch 250/1000\n",
            "2304/2304 [==============================] - 1s 583us/step - loss: 20334.8256 - val_loss: 18193.9887\n",
            "Epoch 251/1000\n",
            "2304/2304 [==============================] - 1s 530us/step - loss: 20293.9275 - val_loss: 17792.9437\n",
            "Epoch 252/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 20567.1465 - val_loss: 15440.0669\n",
            "Epoch 253/1000\n",
            "2304/2304 [==============================] - 1s 450us/step - loss: 20427.0153 - val_loss: 14923.4824\n",
            "Epoch 254/1000\n",
            "2304/2304 [==============================] - 1s 461us/step - loss: 20450.5625 - val_loss: 16042.9484\n",
            "Epoch 255/1000\n",
            "2304/2304 [==============================] - 1s 455us/step - loss: 20198.3318 - val_loss: 16222.9939\n",
            "Epoch 256/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 20533.8341 - val_loss: 16831.9639\n",
            "Epoch 257/1000\n",
            "2304/2304 [==============================] - 1s 509us/step - loss: 20154.9191 - val_loss: 14754.8845\n",
            "Epoch 258/1000\n",
            "2304/2304 [==============================] - 1s 469us/step - loss: 20387.4427 - val_loss: 15878.7856\n",
            "Epoch 259/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 20359.2988 - val_loss: 16003.4819\n",
            "Epoch 260/1000\n",
            "2304/2304 [==============================] - 1s 461us/step - loss: 20531.9542 - val_loss: 16200.7362\n",
            "Epoch 261/1000\n",
            "2304/2304 [==============================] - 1s 454us/step - loss: 20018.3629 - val_loss: 15491.6521\n",
            "Epoch 262/1000\n",
            "2304/2304 [==============================] - 1s 481us/step - loss: 20267.9428 - val_loss: 15069.8928\n",
            "Epoch 263/1000\n",
            "2304/2304 [==============================] - 1s 479us/step - loss: 20530.1369 - val_loss: 15627.3145\n",
            "Epoch 264/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 20294.7257 - val_loss: 17765.7470\n",
            "Epoch 265/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 20360.8740 - val_loss: 14508.3821\n",
            "Epoch 266/1000\n",
            "2304/2304 [==============================] - 1s 425us/step - loss: 20267.8221 - val_loss: 15420.8517\n",
            "Epoch 267/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 19862.5230 - val_loss: 14701.4737\n",
            "Epoch 268/1000\n",
            "2304/2304 [==============================] - 1s 433us/step - loss: 19815.6728 - val_loss: 14743.0286\n",
            "Epoch 269/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 19757.1898 - val_loss: 16036.5053\n",
            "Epoch 270/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 19572.5032 - val_loss: 15336.2828\n",
            "Epoch 271/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 19700.6566 - val_loss: 15040.9445\n",
            "Epoch 272/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 19473.6894 - val_loss: 15602.6384\n",
            "Epoch 273/1000\n",
            "2304/2304 [==============================] - 1s 454us/step - loss: 19906.8170 - val_loss: 14509.2126\n",
            "Epoch 274/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 19699.7736 - val_loss: 15772.0936\n",
            "Epoch 275/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 20105.0729 - val_loss: 14584.7437\n",
            "Epoch 276/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 20147.8612 - val_loss: 15057.5087\n",
            "Epoch 277/1000\n",
            "2304/2304 [==============================] - 1s 454us/step - loss: 19881.5120 - val_loss: 18572.5668\n",
            "Epoch 278/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 19517.4842 - val_loss: 16397.4856\n",
            "Epoch 279/1000\n",
            "2304/2304 [==============================] - 1s 433us/step - loss: 19976.7596 - val_loss: 15108.0453\n",
            "Epoch 280/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 19935.8306 - val_loss: 15692.7591\n",
            "Epoch 281/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 19793.6322 - val_loss: 14389.2686\n",
            "Epoch 282/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 19412.6952 - val_loss: 15312.0001\n",
            "Epoch 283/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 20059.2136 - val_loss: 15273.2969\n",
            "Epoch 284/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 19604.2384 - val_loss: 14420.2558\n",
            "Epoch 285/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 19496.6790 - val_loss: 14708.9673\n",
            "Epoch 286/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 20049.3460 - val_loss: 16034.7254\n",
            "Epoch 287/1000\n",
            "2304/2304 [==============================] - 1s 430us/step - loss: 19478.0735 - val_loss: 14571.8502\n",
            "Epoch 288/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 19667.3767 - val_loss: 14611.5370\n",
            "Epoch 289/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 19504.3439 - val_loss: 14015.6003\n",
            "Epoch 290/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 19758.8318 - val_loss: 16997.5221\n",
            "Epoch 291/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 19601.7732 - val_loss: 17615.9217\n",
            "Epoch 292/1000\n",
            "2304/2304 [==============================] - 1s 427us/step - loss: 19661.4567 - val_loss: 16816.5259\n",
            "Epoch 293/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 19131.7665 - val_loss: 14086.0776\n",
            "Epoch 294/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 19576.5483 - val_loss: 14701.9938\n",
            "Epoch 295/1000\n",
            "2304/2304 [==============================] - 1s 461us/step - loss: 19444.5205 - val_loss: 14263.2803\n",
            "Epoch 296/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 19304.4485 - val_loss: 14911.7827\n",
            "Epoch 297/1000\n",
            "2304/2304 [==============================] - 2s 687us/step - loss: 19703.8128 - val_loss: 16053.4814\n",
            "Epoch 298/1000\n",
            "2304/2304 [==============================] - 1s 462us/step - loss: 19346.9465 - val_loss: 14261.0299\n",
            "Epoch 299/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 19704.9612 - val_loss: 14267.3405\n",
            "Epoch 300/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 19352.9026 - val_loss: 14148.4302\n",
            "Epoch 301/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 19498.7444 - val_loss: 14138.5259\n",
            "Epoch 302/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 18726.3407 - val_loss: 15887.5956\n",
            "Epoch 303/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 19946.6447 - val_loss: 16257.2649\n",
            "Epoch 304/1000\n",
            "2304/2304 [==============================] - 1s 457us/step - loss: 19362.7704 - val_loss: 13983.4914\n",
            "Epoch 305/1000\n",
            "2304/2304 [==============================] - 1s 450us/step - loss: 18790.8474 - val_loss: 14023.9126\n",
            "Epoch 306/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 19160.9730 - val_loss: 14827.6932\n",
            "Epoch 307/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 19190.6534 - val_loss: 18906.2787\n",
            "Epoch 308/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 19401.0639 - val_loss: 14333.4869\n",
            "Epoch 309/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 19238.1993 - val_loss: 19174.5764\n",
            "Epoch 310/1000\n",
            "2304/2304 [==============================] - 1s 450us/step - loss: 20029.8387 - val_loss: 14179.8829\n",
            "Epoch 311/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 18918.1769 - val_loss: 15346.9258\n",
            "Epoch 312/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 19041.3360 - val_loss: 15424.8321\n",
            "Epoch 313/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 19119.5293 - val_loss: 14270.7577\n",
            "Epoch 314/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 19292.8256 - val_loss: 14625.2434\n",
            "Epoch 315/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 19020.3923 - val_loss: 15541.8373\n",
            "Epoch 316/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 19109.0529 - val_loss: 14618.3543\n",
            "Epoch 317/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 18554.5315 - val_loss: 14239.7411\n",
            "Epoch 318/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 19012.3046 - val_loss: 14200.9190\n",
            "Epoch 319/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 18846.4739 - val_loss: 14101.2692\n",
            "Epoch 320/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 18813.7599 - val_loss: 14046.8665\n",
            "Epoch 321/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 18852.2364 - val_loss: 15203.3614\n",
            "Epoch 322/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 19056.3984 - val_loss: 14890.5568\n",
            "Epoch 323/1000\n",
            "2304/2304 [==============================] - 1s 460us/step - loss: 18563.3026 - val_loss: 13836.5927\n",
            "Epoch 324/1000\n",
            "2304/2304 [==============================] - 1s 450us/step - loss: 19340.7887 - val_loss: 14266.8893\n",
            "Epoch 325/1000\n",
            "2304/2304 [==============================] - 1s 450us/step - loss: 19060.3305 - val_loss: 15360.9089\n",
            "Epoch 326/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 18662.2458 - val_loss: 14017.1838\n",
            "Epoch 327/1000\n",
            "2304/2304 [==============================] - 1s 452us/step - loss: 18428.4088 - val_loss: 14745.7661\n",
            "Epoch 328/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 19135.0274 - val_loss: 15207.9820\n",
            "Epoch 329/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 18923.7394 - val_loss: 14965.7481\n",
            "Epoch 330/1000\n",
            "2304/2304 [==============================] - 1s 452us/step - loss: 18535.9474 - val_loss: 17499.9861\n",
            "Epoch 331/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 19013.6725 - val_loss: 15235.5978\n",
            "Epoch 332/1000\n",
            "2304/2304 [==============================] - 1s 458us/step - loss: 18596.5386 - val_loss: 15663.1766\n",
            "Epoch 333/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 18753.9279 - val_loss: 14441.8432\n",
            "Epoch 334/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 18830.9042 - val_loss: 14302.3303\n",
            "Epoch 335/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 18712.8998 - val_loss: 14407.8947\n",
            "Epoch 336/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 18339.9842 - val_loss: 16368.5578\n",
            "Epoch 337/1000\n",
            "2304/2304 [==============================] - 1s 454us/step - loss: 18322.5995 - val_loss: 14554.7695\n",
            "Epoch 338/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 18302.4392 - val_loss: 18285.9036\n",
            "Epoch 339/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 18712.5002 - val_loss: 16307.5702\n",
            "Epoch 340/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 18290.9863 - val_loss: 14239.9206\n",
            "Epoch 341/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 18704.4309 - val_loss: 14550.0324\n",
            "Epoch 342/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 18247.0918 - val_loss: 14879.0659\n",
            "Epoch 343/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 18006.7334 - val_loss: 18404.3097\n",
            "Epoch 344/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 18743.3766 - val_loss: 14351.7088\n",
            "Epoch 345/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 18354.7083 - val_loss: 13809.4760\n",
            "Epoch 346/1000\n",
            "2304/2304 [==============================] - 1s 430us/step - loss: 18344.7377 - val_loss: 14164.0234\n",
            "Epoch 347/1000\n",
            "2304/2304 [==============================] - 1s 450us/step - loss: 17953.9372 - val_loss: 15203.0973\n",
            "Epoch 348/1000\n",
            "2304/2304 [==============================] - 1s 430us/step - loss: 18169.8337 - val_loss: 15557.0146\n",
            "Epoch 349/1000\n",
            "2304/2304 [==============================] - 1s 456us/step - loss: 18846.4769 - val_loss: 13736.5097\n",
            "Epoch 350/1000\n",
            "2304/2304 [==============================] - 1s 432us/step - loss: 18310.2781 - val_loss: 15919.4781\n",
            "Epoch 351/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 17808.3110 - val_loss: 16368.7301\n",
            "Epoch 352/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 18350.3996 - val_loss: 14352.2247\n",
            "Epoch 353/1000\n",
            "2304/2304 [==============================] - 1s 455us/step - loss: 18125.6151 - val_loss: 14588.8044\n",
            "Epoch 354/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 17982.2255 - val_loss: 15111.4960\n",
            "Epoch 355/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 18200.9428 - val_loss: 16779.2044\n",
            "Epoch 356/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 17829.2466 - val_loss: 15074.7010\n",
            "Epoch 357/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 18016.9196 - val_loss: 14864.5632\n",
            "Epoch 358/1000\n",
            "2304/2304 [==============================] - 1s 430us/step - loss: 17915.1799 - val_loss: 24316.4935\n",
            "Epoch 359/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 19223.4313 - val_loss: 14180.9230\n",
            "Epoch 360/1000\n",
            "2304/2304 [==============================] - 1s 426us/step - loss: 18647.8201 - val_loss: 13863.6924\n",
            "Epoch 361/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 18664.2566 - val_loss: 15385.2874\n",
            "Epoch 362/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 17911.7704 - val_loss: 14680.4609\n",
            "Epoch 363/1000\n",
            "2304/2304 [==============================] - 1s 452us/step - loss: 17927.6700 - val_loss: 14011.2587\n",
            "Epoch 364/1000\n",
            "2304/2304 [==============================] - 1s 452us/step - loss: 17879.9066 - val_loss: 14464.9448\n",
            "Epoch 365/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 18198.5349 - val_loss: 15854.3383\n",
            "Epoch 366/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 17806.2551 - val_loss: 16639.1137\n",
            "Epoch 367/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 17713.9328 - val_loss: 15978.6447\n",
            "Epoch 368/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 18191.1775 - val_loss: 13860.3972\n",
            "Epoch 369/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 17839.4774 - val_loss: 16243.3496\n",
            "Epoch 370/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 18056.7944 - val_loss: 13988.9696\n",
            "Epoch 371/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 17830.5053 - val_loss: 13991.4631\n",
            "Epoch 372/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 17826.4593 - val_loss: 14288.8727\n",
            "Epoch 373/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 18230.0502 - val_loss: 13970.4442\n",
            "Epoch 374/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 18149.2701 - val_loss: 13912.5779\n",
            "Epoch 375/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 17991.8544 - val_loss: 14408.1569\n",
            "Epoch 376/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 17852.9588 - val_loss: 13976.1019\n",
            "Epoch 377/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 17220.9854 - val_loss: 14601.7443\n",
            "Epoch 378/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 18052.9831 - val_loss: 14810.8670\n",
            "Epoch 379/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 17936.4085 - val_loss: 15385.9314\n",
            "Epoch 380/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 17604.2571 - val_loss: 22286.7142\n",
            "Epoch 381/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 18617.3345 - val_loss: 16034.6185\n",
            "Epoch 382/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 17403.8869 - val_loss: 14999.4376\n",
            "Epoch 383/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 17939.8127 - val_loss: 14766.4007\n",
            "Epoch 384/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 18240.0339 - val_loss: 14057.3904\n",
            "Epoch 385/1000\n",
            "2304/2304 [==============================] - 1s 454us/step - loss: 17869.7416 - val_loss: 17336.3759\n",
            "Epoch 386/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 17826.6345 - val_loss: 15285.4909\n",
            "Epoch 387/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 17667.2922 - val_loss: 14430.3984\n",
            "Epoch 388/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 17571.7256 - val_loss: 14216.6904\n",
            "Epoch 389/1000\n",
            "2304/2304 [==============================] - 1s 432us/step - loss: 17352.5210 - val_loss: 13842.0403\n",
            "Epoch 390/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 17804.1591 - val_loss: 14489.6196\n",
            "Epoch 391/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 17290.5272 - val_loss: 15556.0982\n",
            "Epoch 392/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 17562.2438 - val_loss: 14057.2289\n",
            "Epoch 393/1000\n",
            "2304/2304 [==============================] - 1s 450us/step - loss: 17475.4925 - val_loss: 14393.1716\n",
            "Epoch 394/1000\n",
            "2304/2304 [==============================] - 1s 421us/step - loss: 17683.2711 - val_loss: 13867.6408\n",
            "Epoch 395/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 18206.1145 - val_loss: 14119.2243\n",
            "Epoch 396/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 17573.8009 - val_loss: 14654.6191\n",
            "Epoch 397/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 17220.1603 - val_loss: 17501.2350\n",
            "Epoch 398/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 17444.1953 - val_loss: 15443.5200\n",
            "Epoch 399/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 17212.9262 - val_loss: 14271.1408\n",
            "Epoch 400/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 18024.3335 - val_loss: 14294.3726\n",
            "Epoch 401/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 17486.2469 - val_loss: 13969.2431\n",
            "Epoch 402/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 17356.3129 - val_loss: 14932.2968\n",
            "Epoch 403/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 17733.6313 - val_loss: 15349.2541\n",
            "Epoch 404/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 17096.2496 - val_loss: 14960.6332\n",
            "Epoch 405/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 17120.7252 - val_loss: 14787.6082\n",
            "Epoch 406/1000\n",
            "2304/2304 [==============================] - 1s 430us/step - loss: 17491.6736 - val_loss: 19178.5432\n",
            "Epoch 407/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 17724.7867 - val_loss: 14122.0443\n",
            "Epoch 408/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 17579.8739 - val_loss: 14003.0985\n",
            "Epoch 409/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 17608.8391 - val_loss: 17843.3101\n",
            "Epoch 410/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 17523.1099 - val_loss: 14959.4707\n",
            "Epoch 411/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 16910.8874 - val_loss: 13747.2737\n",
            "Epoch 412/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 17539.3152 - val_loss: 14720.9098\n",
            "Epoch 413/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 17267.5506 - val_loss: 14258.4516\n",
            "Epoch 414/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 17315.9268 - val_loss: 13593.2258\n",
            "Epoch 415/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 17380.5531 - val_loss: 14079.7826\n",
            "Epoch 416/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 16996.8228 - val_loss: 15113.6179\n",
            "Epoch 417/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 17600.8175 - val_loss: 18986.0353\n",
            "Epoch 418/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 17023.1818 - val_loss: 14341.5397\n",
            "Epoch 419/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 17573.1886 - val_loss: 14370.9430\n",
            "Epoch 420/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 17225.8739 - val_loss: 15407.3638\n",
            "Epoch 421/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 17412.0493 - val_loss: 19036.0672\n",
            "Epoch 422/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 17108.0607 - val_loss: 15606.9727\n",
            "Epoch 423/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 17136.4948 - val_loss: 15391.9444\n",
            "Epoch 424/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 17093.5108 - val_loss: 14448.2228\n",
            "Epoch 425/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 16837.8037 - val_loss: 16118.2474\n",
            "Epoch 426/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 17296.2004 - val_loss: 13944.9400\n",
            "Epoch 427/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 17272.2626 - val_loss: 13772.1651\n",
            "Epoch 428/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 17281.5558 - val_loss: 13642.4159\n",
            "Epoch 429/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 17101.2987 - val_loss: 15898.3358\n",
            "Epoch 430/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 16709.3143 - val_loss: 19334.2600\n",
            "Epoch 431/1000\n",
            "2304/2304 [==============================] - 1s 432us/step - loss: 16868.6854 - val_loss: 16250.8959\n",
            "Epoch 432/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 17385.3112 - val_loss: 13705.7346\n",
            "Epoch 433/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 17247.9291 - val_loss: 14623.1077\n",
            "Epoch 434/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 17188.4737 - val_loss: 13852.3366\n",
            "Epoch 435/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 16656.4663 - val_loss: 14797.9058\n",
            "Epoch 436/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 17156.8052 - val_loss: 13735.2475\n",
            "Epoch 437/1000\n",
            "2304/2304 [==============================] - 1s 433us/step - loss: 17050.5127 - val_loss: 17040.0685\n",
            "Epoch 438/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 16785.3803 - val_loss: 15292.6484\n",
            "Epoch 439/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 16491.9697 - val_loss: 15786.6080\n",
            "Epoch 440/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 17464.6337 - val_loss: 15852.0196\n",
            "Epoch 441/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 17213.6505 - val_loss: 15082.6042\n",
            "Epoch 442/1000\n",
            "2304/2304 [==============================] - 1s 450us/step - loss: 17345.8611 - val_loss: 14912.8041\n",
            "Epoch 443/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 16981.0900 - val_loss: 18065.5751\n",
            "Epoch 444/1000\n",
            "2304/2304 [==============================] - 1s 432us/step - loss: 17532.0109 - val_loss: 16386.4432\n",
            "Epoch 445/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 17591.5213 - val_loss: 14487.9600\n",
            "Epoch 446/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 17624.2621 - val_loss: 16752.8077\n",
            "Epoch 447/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 16998.9168 - val_loss: 13496.9836\n",
            "Epoch 448/1000\n",
            "2304/2304 [==============================] - 1s 430us/step - loss: 16836.7056 - val_loss: 14631.2539\n",
            "Epoch 449/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 16696.3389 - val_loss: 16631.2494\n",
            "Epoch 450/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 16983.9090 - val_loss: 15312.0523\n",
            "Epoch 451/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 16810.2610 - val_loss: 14278.9533\n",
            "Epoch 452/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 17404.3263 - val_loss: 15086.4043\n",
            "Epoch 453/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 17100.2959 - val_loss: 13936.6329\n",
            "Epoch 454/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 16667.1507 - val_loss: 18293.9448\n",
            "Epoch 455/1000\n",
            "2304/2304 [==============================] - ETA: 0s - loss: 17168.9288- ETA: 0s - - 1s 438us/step - loss: 17086.7000 - val_loss: 13579.2260\n",
            "Epoch 456/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 16701.5239 - val_loss: 14569.9128\n",
            "Epoch 457/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 16879.7268 - val_loss: 13863.3398\n",
            "Epoch 458/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 16426.4349 - val_loss: 17490.6424\n",
            "Epoch 459/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 17047.0664 - val_loss: 14906.5276\n",
            "Epoch 460/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 17470.8861 - val_loss: 14052.3652\n",
            "Epoch 461/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 16674.0154 - val_loss: 17727.5517\n",
            "Epoch 462/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 17145.5984 - val_loss: 14692.3786\n",
            "Epoch 463/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 17166.9755 - val_loss: 14124.9136\n",
            "Epoch 464/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 16679.6169 - val_loss: 19373.4150\n",
            "Epoch 465/1000\n",
            "2304/2304 [==============================] - 1s 450us/step - loss: 16774.5541 - val_loss: 14200.0199\n",
            "Epoch 466/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 16595.9005 - val_loss: 14423.6457\n",
            "Epoch 467/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 16689.2204 - val_loss: 14240.4985\n",
            "Epoch 468/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 16708.0954 - val_loss: 14334.9017\n",
            "Epoch 469/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 17191.4972 - val_loss: 13775.6621\n",
            "Epoch 470/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 17505.5673 - val_loss: 13765.9852\n",
            "Epoch 471/1000\n",
            "2304/2304 [==============================] - 1s 456us/step - loss: 17377.3753 - val_loss: 16874.4895\n",
            "Epoch 472/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 16932.0075 - val_loss: 15280.1072\n",
            "Epoch 473/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 16530.4014 - val_loss: 14520.9200\n",
            "Epoch 474/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 17395.5364 - val_loss: 13848.9501\n",
            "Epoch 475/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 16857.5059 - val_loss: 13565.6380\n",
            "Epoch 476/1000\n",
            "2304/2304 [==============================] - 1s 455us/step - loss: 16767.7075 - val_loss: 19872.7868\n",
            "Epoch 477/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 16884.9123 - val_loss: 13176.7210\n",
            "Epoch 478/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 16330.7191 - val_loss: 14813.3151\n",
            "Epoch 479/1000\n",
            "2304/2304 [==============================] - 1s 463us/step - loss: 16560.1846 - val_loss: 13560.4959\n",
            "Epoch 480/1000\n",
            "2304/2304 [==============================] - 1s 452us/step - loss: 16994.8374 - val_loss: 13748.0220\n",
            "Epoch 481/1000\n",
            "2304/2304 [==============================] - 1s 453us/step - loss: 17105.0768 - val_loss: 13977.5572\n",
            "Epoch 482/1000\n",
            "2304/2304 [==============================] - 1s 457us/step - loss: 16926.7186 - val_loss: 15421.4735\n",
            "Epoch 483/1000\n",
            "2304/2304 [==============================] - ETA: 0s - loss: 17416.383 - 1s 442us/step - loss: 17520.7117 - val_loss: 14974.8713\n",
            "Epoch 484/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 17241.7099 - val_loss: 16109.2987\n",
            "Epoch 485/1000\n",
            "2304/2304 [==============================] - 1s 467us/step - loss: 16878.6128 - val_loss: 13340.2037\n",
            "Epoch 486/1000\n",
            "2304/2304 [==============================] - 1s 460us/step - loss: 16567.2597 - val_loss: 13226.7989\n",
            "Epoch 487/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 17009.0485 - val_loss: 14334.8273\n",
            "Epoch 488/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 17224.3196 - val_loss: 15182.8221\n",
            "Epoch 489/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 16113.3428 - val_loss: 14707.3002\n",
            "Epoch 490/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 16157.4614 - val_loss: 17262.7748\n",
            "Epoch 491/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 16754.3682 - val_loss: 17514.4146\n",
            "Epoch 492/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 16435.4573 - val_loss: 13711.0666\n",
            "Epoch 493/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 17039.9159 - val_loss: 15920.7148\n",
            "Epoch 494/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 16618.5890 - val_loss: 13543.7893\n",
            "Epoch 495/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 17146.2448 - val_loss: 18693.5495\n",
            "Epoch 496/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 16916.5060 - val_loss: 13491.6188\n",
            "Epoch 497/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 16322.7569 - val_loss: 14055.7516\n",
            "Epoch 498/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 16738.7356 - val_loss: 13729.1235\n",
            "Epoch 499/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 17037.1458 - val_loss: 19032.3017\n",
            "Epoch 500/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 17037.1399 - val_loss: 13309.6670\n",
            "Epoch 501/1000\n",
            "2304/2304 [==============================] - 1s 453us/step - loss: 16405.3647 - val_loss: 13464.1638\n",
            "Epoch 502/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 17211.2725 - val_loss: 17083.4213\n",
            "Epoch 503/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 17172.4802 - val_loss: 13478.5523\n",
            "Epoch 504/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 16247.5303 - val_loss: 14198.8873\n",
            "Epoch 505/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 16671.5918 - val_loss: 13535.8521\n",
            "Epoch 506/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 16185.6086 - val_loss: 14095.6265\n",
            "Epoch 507/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 16207.7347 - val_loss: 14325.4418\n",
            "Epoch 508/1000\n",
            "2304/2304 [==============================] - 1s 416us/step - loss: 16652.1647 - val_loss: 14851.3673\n",
            "Epoch 509/1000\n",
            "2304/2304 [==============================] - 1s 413us/step - loss: 16606.8829 - val_loss: 14483.6561\n",
            "Epoch 510/1000\n",
            "2304/2304 [==============================] - 1s 416us/step - loss: 16154.6917 - val_loss: 13027.8321\n",
            "Epoch 511/1000\n",
            "2304/2304 [==============================] - 1s 422us/step - loss: 16352.7531 - val_loss: 13074.6578\n",
            "Epoch 512/1000\n",
            "2304/2304 [==============================] - 1s 416us/step - loss: 16269.5398 - val_loss: 15614.6946\n",
            "Epoch 513/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 16844.1695 - val_loss: 13532.4958\n",
            "Epoch 514/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 16391.5720 - val_loss: 13839.0900\n",
            "Epoch 515/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 16910.4774 - val_loss: 13006.5320\n",
            "Epoch 516/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 16441.9044 - val_loss: 13741.3823\n",
            "Epoch 517/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 16175.2031 - val_loss: 13118.6830\n",
            "Epoch 518/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 16029.5415 - val_loss: 13535.7123\n",
            "Epoch 519/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 16822.5800 - val_loss: 12918.1999\n",
            "Epoch 520/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 16400.1417 - val_loss: 13436.6186\n",
            "Epoch 521/1000\n",
            "2304/2304 [==============================] - 1s 471us/step - loss: 16581.6498 - val_loss: 13149.8857\n",
            "Epoch 522/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 16398.8991 - val_loss: 13370.1782\n",
            "Epoch 523/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 16296.1482 - val_loss: 16340.5884\n",
            "Epoch 524/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 16327.9647 - val_loss: 13298.2406\n",
            "Epoch 525/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 16280.1426 - val_loss: 13291.0479\n",
            "Epoch 526/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 16098.8848 - val_loss: 13626.7445\n",
            "Epoch 527/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 16265.7438 - val_loss: 13826.5380\n",
            "Epoch 528/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 15989.9011 - val_loss: 14713.3395\n",
            "Epoch 529/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 15569.1148 - val_loss: 13209.5831\n",
            "Epoch 530/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 16541.1532 - val_loss: 17341.2461\n",
            "Epoch 531/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 16239.2389 - val_loss: 13829.2114\n",
            "Epoch 532/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 16521.4224 - val_loss: 15856.1819\n",
            "Epoch 533/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 15968.5748 - val_loss: 12955.7784\n",
            "Epoch 534/1000\n",
            "2304/2304 [==============================] - 1s 452us/step - loss: 16293.7703 - val_loss: 13159.6920\n",
            "Epoch 535/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 15915.4719 - val_loss: 15236.5337\n",
            "Epoch 536/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 16546.5183 - val_loss: 16853.1425\n",
            "Epoch 537/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 16415.3709 - val_loss: 22590.1958\n",
            "Epoch 538/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 16038.1731 - val_loss: 15478.0320\n",
            "Epoch 539/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 16662.2867 - val_loss: 13633.4050\n",
            "Epoch 540/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 16813.9251 - val_loss: 12660.4432\n",
            "Epoch 541/1000\n",
            "2304/2304 [==============================] - 1s 464us/step - loss: 16527.9992 - val_loss: 14913.9604\n",
            "Epoch 542/1000\n",
            "2304/2304 [==============================] - 1s 431us/step - loss: 16079.3291 - val_loss: 13788.1918\n",
            "Epoch 543/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 16225.2902 - val_loss: 14426.3797\n",
            "Epoch 544/1000\n",
            "2304/2304 [==============================] - 1s 456us/step - loss: 15732.6024 - val_loss: 13636.5850\n",
            "Epoch 545/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 16214.2543 - val_loss: 21259.3888\n",
            "Epoch 546/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 16336.5275 - val_loss: 13642.9841\n",
            "Epoch 547/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 16242.7494 - val_loss: 12891.3443\n",
            "Epoch 548/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 15609.3064 - val_loss: 15241.3289\n",
            "Epoch 549/1000\n",
            "2304/2304 [==============================] - 1s 454us/step - loss: 16055.6001 - val_loss: 15129.6870\n",
            "Epoch 550/1000\n",
            "2304/2304 [==============================] - 1s 456us/step - loss: 16056.1482 - val_loss: 13194.1173\n",
            "Epoch 551/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 16373.1419 - val_loss: 13835.9007\n",
            "Epoch 552/1000\n",
            "2304/2304 [==============================] - 1s 433us/step - loss: 16585.9757 - val_loss: 15642.5804\n",
            "Epoch 553/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 16268.6899 - val_loss: 12619.5854\n",
            "Epoch 554/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 16432.3227 - val_loss: 14910.7167\n",
            "Epoch 555/1000\n",
            "2304/2304 [==============================] - 1s 432us/step - loss: 15964.3666 - val_loss: 13346.9381\n",
            "Epoch 556/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 15907.5030 - val_loss: 12983.0486\n",
            "Epoch 557/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 15918.8584 - val_loss: 13650.5844\n",
            "Epoch 558/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 16200.4612 - val_loss: 12951.2539\n",
            "Epoch 559/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 15835.6661 - val_loss: 14813.2323\n",
            "Epoch 560/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 16570.0578 - val_loss: 14454.0631\n",
            "Epoch 561/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 16869.6169 - val_loss: 13610.7718\n",
            "Epoch 562/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 16840.4261 - val_loss: 13181.9136\n",
            "Epoch 563/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 15979.8033 - val_loss: 13446.4118\n",
            "Epoch 564/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 15563.6671 - val_loss: 13199.9821\n",
            "Epoch 565/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 15908.4225 - val_loss: 15984.1726\n",
            "Epoch 566/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 16004.9399 - val_loss: 13905.7834\n",
            "Epoch 567/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 16389.2974 - val_loss: 13452.7645\n",
            "Epoch 568/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 15584.9971 - val_loss: 14775.5267\n",
            "Epoch 569/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 15664.2811 - val_loss: 13648.0294\n",
            "Epoch 570/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 16375.2549 - val_loss: 13240.0203\n",
            "Epoch 571/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 15903.5278 - val_loss: 14575.3229\n",
            "Epoch 572/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 16540.2915 - val_loss: 12986.2193\n",
            "Epoch 573/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 15546.8738 - val_loss: 12724.5387\n",
            "Epoch 574/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 15573.6981 - val_loss: 14370.9492\n",
            "Epoch 575/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 15998.9777 - val_loss: 14381.9216\n",
            "Epoch 576/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 16236.6067 - val_loss: 13139.3926\n",
            "Epoch 577/1000\n",
            "2304/2304 [==============================] - 1s 453us/step - loss: 16401.3169 - val_loss: 12909.4291\n",
            "Epoch 578/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 15951.6085 - val_loss: 13372.4539\n",
            "Epoch 579/1000\n",
            "2304/2304 [==============================] - ETA: 0s - loss: 15390.301 - 1s 447us/step - loss: 15447.2109 - val_loss: 16080.7027\n",
            "Epoch 580/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 15932.6666 - val_loss: 13824.2292\n",
            "Epoch 581/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 15664.1162 - val_loss: 14778.0713\n",
            "Epoch 582/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 15933.7029 - val_loss: 13003.9517\n",
            "Epoch 583/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 15956.3189 - val_loss: 16177.6614\n",
            "Epoch 584/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 15874.3583 - val_loss: 13080.2921\n",
            "Epoch 585/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 16791.4277 - val_loss: 14088.6852\n",
            "Epoch 586/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 15705.0799 - val_loss: 18454.0310\n",
            "Epoch 587/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 15808.1309 - val_loss: 16820.5833\n",
            "Epoch 588/1000\n",
            "2304/2304 [==============================] - 1s 464us/step - loss: 16183.8922 - val_loss: 14711.2256\n",
            "Epoch 589/1000\n",
            "2304/2304 [==============================] - 1s 455us/step - loss: 15707.8248 - val_loss: 13111.5689\n",
            "Epoch 590/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 16598.3475 - val_loss: 15295.8216\n",
            "Epoch 591/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 15327.5790 - val_loss: 13901.1989\n",
            "Epoch 592/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 15704.7646 - val_loss: 13032.4837\n",
            "Epoch 593/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 15951.6286 - val_loss: 13004.5162\n",
            "Epoch 594/1000\n",
            "2304/2304 [==============================] - 1s 457us/step - loss: 15690.0711 - val_loss: 12766.9858\n",
            "Epoch 595/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 15764.8322 - val_loss: 14098.1799\n",
            "Epoch 596/1000\n",
            "2304/2304 [==============================] - 1s 450us/step - loss: 16039.9761 - val_loss: 14123.3657\n",
            "Epoch 597/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 16197.0552 - val_loss: 13257.4783\n",
            "Epoch 598/1000\n",
            "2304/2304 [==============================] - 1s 455us/step - loss: 15653.8917 - val_loss: 13044.1128\n",
            "Epoch 599/1000\n",
            "2304/2304 [==============================] - 1s 461us/step - loss: 16027.9724 - val_loss: 14400.0111\n",
            "Epoch 600/1000\n",
            "2304/2304 [==============================] - 1s 463us/step - loss: 15569.4053 - val_loss: 14585.1445\n",
            "Epoch 601/1000\n",
            "2304/2304 [==============================] - 1s 453us/step - loss: 16236.5629 - val_loss: 14213.7991\n",
            "Epoch 602/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 15410.8726 - val_loss: 13744.9428\n",
            "Epoch 603/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 15623.0107 - val_loss: 13769.4555\n",
            "Epoch 604/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 15422.4580 - val_loss: 13720.9273\n",
            "Epoch 605/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 15629.3536 - val_loss: 13780.4440\n",
            "Epoch 606/1000\n",
            "2304/2304 [==============================] - ETA: 0s - loss: 15512.328 - 1s 449us/step - loss: 15667.5894 - val_loss: 15107.2038\n",
            "Epoch 607/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 15842.8541 - val_loss: 15396.6564\n",
            "Epoch 608/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 16343.3226 - val_loss: 16418.3831\n",
            "Epoch 609/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 15627.2895 - val_loss: 13080.5057\n",
            "Epoch 610/1000\n",
            "2304/2304 [==============================] - 1s 429us/step - loss: 16138.2899 - val_loss: 13839.8605\n",
            "Epoch 611/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 15795.7646 - val_loss: 14323.5030\n",
            "Epoch 612/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 16000.4406 - val_loss: 14379.4820\n",
            "Epoch 613/1000\n",
            "2304/2304 [==============================] - 1s 432us/step - loss: 15908.1178 - val_loss: 12850.5682\n",
            "Epoch 614/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 16145.5608 - val_loss: 13584.1879\n",
            "Epoch 615/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 15431.5824 - val_loss: 13392.1331\n",
            "Epoch 616/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 16703.4658 - val_loss: 14792.3624\n",
            "Epoch 617/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 15772.0554 - val_loss: 15436.8464\n",
            "Epoch 618/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 15374.9280 - val_loss: 13229.2396\n",
            "Epoch 619/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 15145.3295 - val_loss: 14809.5443\n",
            "Epoch 620/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 15543.2908 - val_loss: 16547.6276\n",
            "Epoch 621/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 15959.9643 - val_loss: 16376.9515\n",
            "Epoch 622/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 15781.9054 - val_loss: 15017.2809\n",
            "Epoch 623/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 15574.1608 - val_loss: 12977.8039\n",
            "Epoch 624/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 15664.0746 - val_loss: 16512.8301\n",
            "Epoch 625/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 15434.6600 - val_loss: 13110.2442\n",
            "Epoch 626/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 15833.0265 - val_loss: 13771.7392\n",
            "Epoch 627/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 15141.2832 - val_loss: 12895.8720\n",
            "Epoch 628/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 15806.2560 - val_loss: 12599.8844\n",
            "Epoch 629/1000\n",
            "2304/2304 [==============================] - 1s 456us/step - loss: 15253.5951 - val_loss: 15702.9138\n",
            "Epoch 630/1000\n",
            "2304/2304 [==============================] - ETA: 0s - loss: 16220.005 - 1s 446us/step - loss: 16211.7160 - val_loss: 13587.7423\n",
            "Epoch 631/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 15374.0106 - val_loss: 16109.5302\n",
            "Epoch 632/1000\n",
            "2304/2304 [==============================] - 1s 433us/step - loss: 15973.8315 - val_loss: 14559.4370\n",
            "Epoch 633/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 15757.8239 - val_loss: 14605.0098\n",
            "Epoch 634/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 15382.4610 - val_loss: 15446.6752\n",
            "Epoch 635/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 15981.6069 - val_loss: 14574.5966\n",
            "Epoch 636/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 15255.1359 - val_loss: 16051.3238\n",
            "Epoch 637/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 15448.6940 - val_loss: 13010.1859\n",
            "Epoch 638/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 15537.2544 - val_loss: 14263.5028\n",
            "Epoch 639/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 15717.0864 - val_loss: 13682.7131\n",
            "Epoch 640/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 15358.8598 - val_loss: 13410.3975\n",
            "Epoch 641/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 15642.4729 - val_loss: 13778.9329\n",
            "Epoch 642/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 16350.4903 - val_loss: 21586.3186\n",
            "Epoch 643/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 15697.2444 - val_loss: 13705.7611\n",
            "Epoch 644/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 15046.5153 - val_loss: 16719.6757\n",
            "Epoch 645/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 15784.5210 - val_loss: 13796.9106\n",
            "Epoch 646/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 15669.4205 - val_loss: 12644.5263\n",
            "Epoch 647/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 15642.5598 - val_loss: 13163.1053\n",
            "Epoch 648/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 15469.4455 - val_loss: 14157.4993\n",
            "Epoch 649/1000\n",
            "2304/2304 [==============================] - 1s 431us/step - loss: 15148.3762 - val_loss: 12870.2361\n",
            "Epoch 650/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 15614.2960 - val_loss: 12830.4788\n",
            "Epoch 651/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 15455.5890 - val_loss: 14309.9376\n",
            "Epoch 652/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 15504.0487 - val_loss: 12620.4909\n",
            "Epoch 653/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 15521.0770 - val_loss: 13617.4397\n",
            "Epoch 654/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 15487.8799 - val_loss: 13259.1685\n",
            "Epoch 655/1000\n",
            "2304/2304 [==============================] - 1s 433us/step - loss: 15204.8147 - val_loss: 13958.5722\n",
            "Epoch 656/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 15702.2916 - val_loss: 13165.9372\n",
            "Epoch 657/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 15200.5446 - val_loss: 14146.9903\n",
            "Epoch 658/1000\n",
            "2304/2304 [==============================] - 1s 424us/step - loss: 15479.8287 - val_loss: 13355.3974\n",
            "Epoch 659/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 15440.6843 - val_loss: 13331.1294\n",
            "Epoch 660/1000\n",
            "2304/2304 [==============================] - 1s 427us/step - loss: 15174.4019 - val_loss: 12858.8573\n",
            "Epoch 661/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 15110.9219 - val_loss: 12799.9921\n",
            "Epoch 662/1000\n",
            "2304/2304 [==============================] - ETA: 0s - loss: 15598.324 - 1s 448us/step - loss: 15515.2419 - val_loss: 12942.6975\n",
            "Epoch 663/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 16275.1000 - val_loss: 16717.4047\n",
            "Epoch 664/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 16169.6125 - val_loss: 12684.8459\n",
            "Epoch 665/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 15119.5771 - val_loss: 17778.7259\n",
            "Epoch 666/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 15477.4023 - val_loss: 13685.2982\n",
            "Epoch 667/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 15982.5753 - val_loss: 14503.3253\n",
            "Epoch 668/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 15682.8486 - val_loss: 15272.2460\n",
            "Epoch 669/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 15223.0342 - val_loss: 12861.6631\n",
            "Epoch 670/1000\n",
            "2304/2304 [==============================] - 1s 458us/step - loss: 15199.3037 - val_loss: 12720.9584\n",
            "Epoch 671/1000\n",
            "2304/2304 [==============================] - 1s 432us/step - loss: 15367.5364 - val_loss: 12661.7466\n",
            "Epoch 672/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 15171.9637 - val_loss: 13398.3861\n",
            "Epoch 673/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 15272.5848 - val_loss: 13891.8174\n",
            "Epoch 674/1000\n",
            "2304/2304 [==============================] - 1s 457us/step - loss: 15364.4168 - val_loss: 13129.6698\n",
            "Epoch 675/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 15352.5513 - val_loss: 13137.0173\n",
            "Epoch 676/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 15420.8494 - val_loss: 14306.8728\n",
            "Epoch 677/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 15816.9606 - val_loss: 13225.2205\n",
            "Epoch 678/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 15520.9441 - val_loss: 12961.2857\n",
            "Epoch 679/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 16166.1388 - val_loss: 13093.5504\n",
            "Epoch 680/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 15809.7020 - val_loss: 12755.8231\n",
            "Epoch 681/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 15275.4096 - val_loss: 14574.4372\n",
            "Epoch 682/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 15262.1467 - val_loss: 15008.6220\n",
            "Epoch 683/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 15541.8515 - val_loss: 12507.0198\n",
            "Epoch 684/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 15458.2967 - val_loss: 12919.8445\n",
            "Epoch 685/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 15089.8102 - val_loss: 13483.9403\n",
            "Epoch 686/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 15078.7916 - val_loss: 13308.9251\n",
            "Epoch 687/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 14969.1277 - val_loss: 15465.7025\n",
            "Epoch 688/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 15335.7592 - val_loss: 12952.5697\n",
            "Epoch 689/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 15527.9751 - val_loss: 17052.4783\n",
            "Epoch 690/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 15339.5878 - val_loss: 14415.3618\n",
            "Epoch 691/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 15469.8665 - val_loss: 14247.9914\n",
            "Epoch 692/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 15702.3830 - val_loss: 17907.0751\n",
            "Epoch 693/1000\n",
            "2304/2304 [==============================] - 1s 432us/step - loss: 15765.4085 - val_loss: 13254.7512\n",
            "Epoch 694/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 15332.0656 - val_loss: 18456.6299\n",
            "Epoch 695/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 15447.8551 - val_loss: 12613.2257\n",
            "Epoch 696/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 14687.8422 - val_loss: 13083.2457\n",
            "Epoch 697/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 15330.3883 - val_loss: 18014.6404\n",
            "Epoch 698/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 15781.9598 - val_loss: 16162.5326\n",
            "Epoch 699/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 15493.8309 - val_loss: 17285.5977\n",
            "Epoch 700/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 15423.0763 - val_loss: 12625.9207\n",
            "Epoch 701/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 15297.0811 - val_loss: 13373.4003\n",
            "Epoch 702/1000\n",
            "2304/2304 [==============================] - 1s 433us/step - loss: 15426.0078 - val_loss: 13488.4394\n",
            "Epoch 703/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 15466.9557 - val_loss: 14845.1572\n",
            "Epoch 704/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 15065.8811 - val_loss: 12732.2395\n",
            "Epoch 705/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 15026.7516 - val_loss: 13223.4333\n",
            "Epoch 706/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 15230.2854 - val_loss: 14756.2749\n",
            "Epoch 707/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 15406.9381 - val_loss: 13308.5025\n",
            "Epoch 708/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 15260.3629 - val_loss: 18116.0258\n",
            "Epoch 709/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 15283.3038 - val_loss: 13337.3922\n",
            "Epoch 710/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 15137.5314 - val_loss: 13265.3038\n",
            "Epoch 711/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 15759.4561 - val_loss: 14528.8233\n",
            "Epoch 712/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 15241.5850 - val_loss: 12762.3783\n",
            "Epoch 713/1000\n",
            "2304/2304 [==============================] - 1s 429us/step - loss: 14968.4679 - val_loss: 13901.8424\n",
            "Epoch 714/1000\n",
            "2304/2304 [==============================] - 1s 433us/step - loss: 15471.8470 - val_loss: 13121.6925\n",
            "Epoch 715/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 15340.8782 - val_loss: 16421.3447\n",
            "Epoch 716/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 15203.0577 - val_loss: 13425.4123\n",
            "Epoch 717/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 15364.1613 - val_loss: 14678.5288\n",
            "Epoch 718/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 15190.8276 - val_loss: 13293.1317\n",
            "Epoch 719/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 15485.2657 - val_loss: 16684.7799\n",
            "Epoch 720/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 16062.7201 - val_loss: 12756.5438\n",
            "Epoch 721/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 15582.1366 - val_loss: 13934.6589\n",
            "Epoch 722/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 14930.4560 - val_loss: 14532.9120\n",
            "Epoch 723/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 15068.7575 - val_loss: 12634.7672\n",
            "Epoch 724/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 15363.4014 - val_loss: 13434.6976\n",
            "Epoch 725/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 15257.4327 - val_loss: 18779.9918\n",
            "Epoch 726/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 15877.7786 - val_loss: 13005.0797\n",
            "Epoch 727/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 15261.8529 - val_loss: 12943.7489\n",
            "Epoch 728/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 15631.8654 - val_loss: 12685.7935\n",
            "Epoch 729/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 15082.9631 - val_loss: 12853.9259\n",
            "Epoch 730/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 14789.6620 - val_loss: 13291.1079\n",
            "Epoch 731/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 14779.1322 - val_loss: 12923.7221\n",
            "Epoch 732/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 14957.5461 - val_loss: 14639.1517\n",
            "Epoch 733/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 15424.5130 - val_loss: 12906.5334\n",
            "Epoch 734/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 15092.7149 - val_loss: 12938.7308\n",
            "Epoch 735/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 14993.9403 - val_loss: 13545.9049\n",
            "Epoch 736/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 14567.7017 - val_loss: 13553.1889\n",
            "Epoch 737/1000\n",
            "2304/2304 [==============================] - 1s 452us/step - loss: 15193.0467 - val_loss: 16555.1944\n",
            "Epoch 738/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 15208.2199 - val_loss: 13473.8713\n",
            "Epoch 739/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 15558.0719 - val_loss: 13306.9156\n",
            "Epoch 740/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 15205.8590 - val_loss: 13603.1274\n",
            "Epoch 741/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 14711.1822 - val_loss: 17975.5598\n",
            "Epoch 742/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 15439.0352 - val_loss: 18252.7317\n",
            "Epoch 743/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 14858.0257 - val_loss: 13080.7335\n",
            "Epoch 744/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 15334.4735 - val_loss: 12367.6314\n",
            "Epoch 745/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 15592.4208 - val_loss: 12456.6742\n",
            "Epoch 746/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 15372.3296 - val_loss: 13681.8867\n",
            "Epoch 747/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 15552.5056 - val_loss: 13359.9924\n",
            "Epoch 748/1000\n",
            "2304/2304 [==============================] - 1s 455us/step - loss: 15025.2245 - val_loss: 13198.7190\n",
            "Epoch 749/1000\n",
            "2304/2304 [==============================] - 1s 431us/step - loss: 15587.6711 - val_loss: 13291.3897\n",
            "Epoch 750/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 15234.3599 - val_loss: 13104.8654\n",
            "Epoch 751/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 15286.4515 - val_loss: 13389.0263\n",
            "Epoch 752/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 15011.1919 - val_loss: 13671.0663\n",
            "Epoch 753/1000\n",
            "2304/2304 [==============================] - 1s 431us/step - loss: 14678.4676 - val_loss: 13171.7875\n",
            "Epoch 754/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 14898.6622 - val_loss: 16745.6186\n",
            "Epoch 755/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 14864.0150 - val_loss: 14502.9875\n",
            "Epoch 756/1000\n",
            "2304/2304 [==============================] - 1s 433us/step - loss: 14996.6706 - val_loss: 14170.1225\n",
            "Epoch 757/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 14958.4556 - val_loss: 13103.1940\n",
            "Epoch 758/1000\n",
            "2304/2304 [==============================] - 1s 429us/step - loss: 14827.0645 - val_loss: 12728.4479\n",
            "Epoch 759/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 15163.0861 - val_loss: 13287.7952\n",
            "Epoch 760/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 14740.0526 - val_loss: 12897.9880\n",
            "Epoch 761/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 14966.5553 - val_loss: 13621.3832\n",
            "Epoch 762/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 14799.1578 - val_loss: 14286.3744\n",
            "Epoch 763/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 14436.9415 - val_loss: 13498.1127\n",
            "Epoch 764/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 15144.7726 - val_loss: 12865.2890\n",
            "Epoch 765/1000\n",
            "2304/2304 [==============================] - 1s 447us/step - loss: 15369.3907 - val_loss: 13159.7846\n",
            "Epoch 766/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 14932.8306 - val_loss: 13319.9050\n",
            "Epoch 767/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 14700.5915 - val_loss: 12496.0247\n",
            "Epoch 768/1000\n",
            "2304/2304 [==============================] - 1s 432us/step - loss: 14422.4766 - val_loss: 12903.3622\n",
            "Epoch 769/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 14772.8422 - val_loss: 12729.0690\n",
            "Epoch 770/1000\n",
            "2304/2304 [==============================] - ETA: 0s - loss: 15411.607 - 1s 442us/step - loss: 15346.0232 - val_loss: 14042.6256\n",
            "Epoch 771/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 15231.9011 - val_loss: 13969.7030\n",
            "Epoch 772/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 15155.9134 - val_loss: 14454.8772\n",
            "Epoch 773/1000\n",
            "2304/2304 [==============================] - 1s 422us/step - loss: 15267.4308 - val_loss: 13259.2004\n",
            "Epoch 774/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 14596.1594 - val_loss: 13166.8524\n",
            "Epoch 775/1000\n",
            "2304/2304 [==============================] - 1s 420us/step - loss: 14974.0176 - val_loss: 15539.5823\n",
            "Epoch 776/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 15169.9119 - val_loss: 13228.7943\n",
            "Epoch 777/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 14630.1758 - val_loss: 13663.6288\n",
            "Epoch 778/1000\n",
            "2304/2304 [==============================] - 1s 456us/step - loss: 14674.2638 - val_loss: 12558.5938\n",
            "Epoch 779/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 14920.9787 - val_loss: 13532.3238\n",
            "Epoch 780/1000\n",
            "2304/2304 [==============================] - 1s 430us/step - loss: 15182.5596 - val_loss: 15951.0021\n",
            "Epoch 781/1000\n",
            "2304/2304 [==============================] - 1s 424us/step - loss: 14665.4194 - val_loss: 12908.2029\n",
            "Epoch 782/1000\n",
            "2304/2304 [==============================] - 1s 426us/step - loss: 14690.0533 - val_loss: 14167.9302\n",
            "Epoch 783/1000\n",
            "2304/2304 [==============================] - 1s 420us/step - loss: 14653.5695 - val_loss: 17030.5262\n",
            "Epoch 784/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 15122.4909 - val_loss: 12568.5641\n",
            "Epoch 785/1000\n",
            "2304/2304 [==============================] - 1s 455us/step - loss: 15265.6583 - val_loss: 12658.0560\n",
            "Epoch 786/1000\n",
            "2304/2304 [==============================] - 1s 461us/step - loss: 14948.2878 - val_loss: 13892.8752\n",
            "Epoch 787/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 14933.4436 - val_loss: 14457.1670\n",
            "Epoch 788/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 15085.2040 - val_loss: 13747.4289\n",
            "Epoch 789/1000\n",
            "2304/2304 [==============================] - 1s 431us/step - loss: 15379.0492 - val_loss: 19403.6576\n",
            "Epoch 790/1000\n",
            "2304/2304 [==============================] - 1s 425us/step - loss: 15351.0965 - val_loss: 15456.3321\n",
            "Epoch 791/1000\n",
            "2304/2304 [==============================] - 1s 421us/step - loss: 14805.4371 - val_loss: 12852.0827\n",
            "Epoch 792/1000\n",
            "2304/2304 [==============================] - 1s 430us/step - loss: 14794.1490 - val_loss: 12984.7817\n",
            "Epoch 793/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 14434.4702 - val_loss: 12845.6965\n",
            "Epoch 794/1000\n",
            "2304/2304 [==============================] - 1s 455us/step - loss: 14672.0893 - val_loss: 13594.8156\n",
            "Epoch 795/1000\n",
            "2304/2304 [==============================] - 1s 452us/step - loss: 14665.5351 - val_loss: 13367.0068\n",
            "Epoch 796/1000\n",
            "2304/2304 [==============================] - 1s 442us/step - loss: 14691.3304 - val_loss: 12902.3428\n",
            "Epoch 797/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 15322.3794 - val_loss: 13206.3453\n",
            "Epoch 798/1000\n",
            "2304/2304 [==============================] - 1s 428us/step - loss: 14591.8013 - val_loss: 12691.5457\n",
            "Epoch 799/1000\n",
            "2304/2304 [==============================] - 1s 423us/step - loss: 14238.9320 - val_loss: 12883.0565\n",
            "Epoch 800/1000\n",
            "2304/2304 [==============================] - 1s 422us/step - loss: 14562.4019 - val_loss: 13239.7346\n",
            "Epoch 801/1000\n",
            "2304/2304 [==============================] - 1s 422us/step - loss: 14895.1009 - val_loss: 12925.1134\n",
            "Epoch 802/1000\n",
            "2304/2304 [==============================] - 1s 426us/step - loss: 14640.8927 - val_loss: 12759.0829\n",
            "Epoch 803/1000\n",
            "2304/2304 [==============================] - 1s 418us/step - loss: 14646.1457 - val_loss: 12718.9311\n",
            "Epoch 804/1000\n",
            "2304/2304 [==============================] - 1s 422us/step - loss: 14635.7928 - val_loss: 12636.7899\n",
            "Epoch 805/1000\n",
            "2304/2304 [==============================] - 1s 424us/step - loss: 13996.3517 - val_loss: 14381.3851\n",
            "Epoch 806/1000\n",
            "2304/2304 [==============================] - 1s 428us/step - loss: 14318.8125 - val_loss: 15468.8791\n",
            "Epoch 807/1000\n",
            "2304/2304 [==============================] - 1s 443us/step - loss: 14880.0421 - val_loss: 13126.8431\n",
            "Epoch 808/1000\n",
            "2304/2304 [==============================] - 1s 451us/step - loss: 15080.8034 - val_loss: 14136.3962\n",
            "Epoch 809/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 15469.5417 - val_loss: 12694.9700\n",
            "Epoch 810/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 14256.0116 - val_loss: 12779.1585\n",
            "Epoch 811/1000\n",
            "2304/2304 [==============================] - 1s 422us/step - loss: 15062.1193 - val_loss: 13845.3082\n",
            "Epoch 812/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 14080.0018 - val_loss: 13449.0193\n",
            "Epoch 813/1000\n",
            "2304/2304 [==============================] - 1s 419us/step - loss: 14612.0249 - val_loss: 13226.6961\n",
            "Epoch 814/1000\n",
            "2304/2304 [==============================] - 1s 419us/step - loss: 14793.5876 - val_loss: 12672.4397\n",
            "Epoch 815/1000\n",
            "2304/2304 [==============================] - 1s 424us/step - loss: 14473.2528 - val_loss: 12693.7991\n",
            "Epoch 816/1000\n",
            "2304/2304 [==============================] - 1s 456us/step - loss: 14533.8183 - val_loss: 13692.2471\n",
            "Epoch 817/1000\n",
            "2304/2304 [==============================] - 1s 428us/step - loss: 14729.4543 - val_loss: 13083.3531\n",
            "Epoch 818/1000\n",
            "2304/2304 [==============================] - 1s 423us/step - loss: 14497.7936 - val_loss: 13903.4400\n",
            "Epoch 819/1000\n",
            "2304/2304 [==============================] - 1s 416us/step - loss: 14109.7411 - val_loss: 13386.7339\n",
            "Epoch 820/1000\n",
            "2304/2304 [==============================] - 1s 423us/step - loss: 14994.6687 - val_loss: 14384.5567\n",
            "Epoch 821/1000\n",
            "2304/2304 [==============================] - 1s 424us/step - loss: 14667.1439 - val_loss: 16717.5792\n",
            "Epoch 822/1000\n",
            "2304/2304 [==============================] - 1s 421us/step - loss: 15194.1799 - val_loss: 12673.5339\n",
            "Epoch 823/1000\n",
            "2304/2304 [==============================] - 1s 424us/step - loss: 14383.1840 - val_loss: 13179.6093\n",
            "Epoch 824/1000\n",
            "2304/2304 [==============================] - 1s 448us/step - loss: 14762.0785 - val_loss: 12920.0712\n",
            "Epoch 825/1000\n",
            "2304/2304 [==============================] - 1s 426us/step - loss: 14621.4354 - val_loss: 13191.5815\n",
            "Epoch 826/1000\n",
            "2304/2304 [==============================] - 1s 432us/step - loss: 14784.9669 - val_loss: 12863.7764\n",
            "Epoch 827/1000\n",
            "2304/2304 [==============================] - 1s 416us/step - loss: 14490.9969 - val_loss: 12752.3748\n",
            "Epoch 828/1000\n",
            "2304/2304 [==============================] - 1s 420us/step - loss: 14351.1834 - val_loss: 12576.6446\n",
            "Epoch 829/1000\n",
            "2304/2304 [==============================] - 1s 428us/step - loss: 15036.8720 - val_loss: 12418.5804\n",
            "Epoch 830/1000\n",
            "2304/2304 [==============================] - 1s 413us/step - loss: 14464.0178 - val_loss: 12871.3090\n",
            "Epoch 831/1000\n",
            "2304/2304 [==============================] - 1s 415us/step - loss: 14654.7483 - val_loss: 13201.5221\n",
            "Epoch 832/1000\n",
            "2304/2304 [==============================] - 1s 424us/step - loss: 14462.2237 - val_loss: 13925.0163\n",
            "Epoch 833/1000\n",
            "2304/2304 [==============================] - 1s 423us/step - loss: 14949.5650 - val_loss: 13039.8272\n",
            "Epoch 834/1000\n",
            "2304/2304 [==============================] - 1s 416us/step - loss: 14270.4275 - val_loss: 12572.5281\n",
            "Epoch 835/1000\n",
            "2304/2304 [==============================] - 1s 426us/step - loss: 14900.3856 - val_loss: 12620.9649\n",
            "Epoch 836/1000\n",
            "2304/2304 [==============================] - 1s 409us/step - loss: 14709.6670 - val_loss: 12989.1388\n",
            "Epoch 837/1000\n",
            "2304/2304 [==============================] - 1s 429us/step - loss: 14657.4319 - val_loss: 13228.2369\n",
            "Epoch 838/1000\n",
            "2304/2304 [==============================] - 1s 472us/step - loss: 14724.9100 - val_loss: 12757.6617\n",
            "Epoch 839/1000\n",
            "2304/2304 [==============================] - 1s 430us/step - loss: 14601.4974 - val_loss: 12417.1430\n",
            "Epoch 840/1000\n",
            "2304/2304 [==============================] - 1s 426us/step - loss: 14986.3101 - val_loss: 17222.0426\n",
            "Epoch 841/1000\n",
            "2304/2304 [==============================] - 1s 411us/step - loss: 15089.0709 - val_loss: 12555.9500\n",
            "Epoch 842/1000\n",
            "2304/2304 [==============================] - 1s 416us/step - loss: 14993.7458 - val_loss: 14066.9829\n",
            "Epoch 843/1000\n",
            "2304/2304 [==============================] - 1s 415us/step - loss: 14532.6220 - val_loss: 18880.1531\n",
            "Epoch 844/1000\n",
            "2304/2304 [==============================] - 1s 415us/step - loss: 14584.9105 - val_loss: 13635.9832\n",
            "Epoch 845/1000\n",
            "2304/2304 [==============================] - 1s 422us/step - loss: 14396.5144 - val_loss: 12778.6250\n",
            "Epoch 846/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 14060.4311 - val_loss: 13225.5006\n",
            "Epoch 847/1000\n",
            "2304/2304 [==============================] - 1s 429us/step - loss: 14654.3758 - val_loss: 13023.3650\n",
            "Epoch 848/1000\n",
            "2304/2304 [==============================] - 1s 420us/step - loss: 14654.8375 - val_loss: 13103.5657\n",
            "Epoch 849/1000\n",
            "2304/2304 [==============================] - 1s 431us/step - loss: 14830.6239 - val_loss: 13058.2414\n",
            "Epoch 850/1000\n",
            "2304/2304 [==============================] - 1s 413us/step - loss: 14764.2105 - val_loss: 13815.4281\n",
            "Epoch 851/1000\n",
            "2304/2304 [==============================] - 1s 419us/step - loss: 14613.9552 - val_loss: 13237.9735\n",
            "Epoch 852/1000\n",
            "2304/2304 [==============================] - 1s 418us/step - loss: 14611.7756 - val_loss: 13520.5362\n",
            "Epoch 853/1000\n",
            "2304/2304 [==============================] - 1s 422us/step - loss: 14431.8364 - val_loss: 13894.3668\n",
            "Epoch 854/1000\n",
            "2304/2304 [==============================] - 1s 427us/step - loss: 15137.1521 - val_loss: 22284.5248\n",
            "Epoch 855/1000\n",
            "2304/2304 [==============================] - 1s 432us/step - loss: 14813.4715 - val_loss: 13260.7255\n",
            "Epoch 856/1000\n",
            "2304/2304 [==============================] - 1s 413us/step - loss: 14475.8784 - val_loss: 13210.7836\n",
            "Epoch 857/1000\n",
            "2304/2304 [==============================] - 1s 427us/step - loss: 14933.4577 - val_loss: 12749.1952\n",
            "Epoch 858/1000\n",
            "2304/2304 [==============================] - 1s 412us/step - loss: 14291.2518 - val_loss: 14971.0328\n",
            "Epoch 859/1000\n",
            "2304/2304 [==============================] - 1s 441us/step - loss: 15208.3715 - val_loss: 15258.7614\n",
            "Epoch 860/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 14987.8951 - val_loss: 13586.2548\n",
            "Epoch 861/1000\n",
            "2304/2304 [==============================] - 1s 430us/step - loss: 14492.0720 - val_loss: 17675.6073\n",
            "Epoch 862/1000\n",
            "2304/2304 [==============================] - 1s 425us/step - loss: 14506.5116 - val_loss: 12518.2817\n",
            "Epoch 863/1000\n",
            "2304/2304 [==============================] - 1s 429us/step - loss: 14188.5038 - val_loss: 13342.0729\n",
            "Epoch 864/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 15359.8370 - val_loss: 16495.8379\n",
            "Epoch 865/1000\n",
            "2304/2304 [==============================] - 1s 435us/step - loss: 14965.1403 - val_loss: 13083.3793\n",
            "Epoch 866/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 14175.7473 - val_loss: 13919.3206\n",
            "Epoch 867/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 14389.9764 - val_loss: 13285.3221\n",
            "Epoch 868/1000\n",
            "2304/2304 [==============================] - 1s 439us/step - loss: 14221.4755 - val_loss: 16674.3418\n",
            "Epoch 869/1000\n",
            "2304/2304 [==============================] - 1s 418us/step - loss: 13982.3276 - val_loss: 14725.3013\n",
            "Epoch 870/1000\n",
            "2304/2304 [==============================] - 1s 370us/step - loss: 14150.5493 - val_loss: 12991.6504\n",
            "Epoch 871/1000\n",
            "2304/2304 [==============================] - 1s 369us/step - loss: 14241.1971 - val_loss: 14242.6713\n",
            "Epoch 872/1000\n",
            "2304/2304 [==============================] - 1s 372us/step - loss: 14235.1650 - val_loss: 13106.2846\n",
            "Epoch 873/1000\n",
            "2304/2304 [==============================] - 1s 382us/step - loss: 14888.9844 - val_loss: 13805.2642\n",
            "Epoch 874/1000\n",
            "2304/2304 [==============================] - 1s 380us/step - loss: 14627.0407 - val_loss: 13571.2920\n",
            "Epoch 875/1000\n",
            "2304/2304 [==============================] - 1s 371us/step - loss: 14100.9699 - val_loss: 13488.7944\n",
            "Epoch 876/1000\n",
            "2304/2304 [==============================] - 1s 428us/step - loss: 14497.7654 - val_loss: 12479.8602\n",
            "Epoch 877/1000\n",
            "2304/2304 [==============================] - 1s 449us/step - loss: 14594.8237 - val_loss: 12449.0825\n",
            "Epoch 878/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 14203.2660 - val_loss: 12609.4652\n",
            "Epoch 879/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 14727.8350 - val_loss: 12740.9682\n",
            "Epoch 880/1000\n",
            "2304/2304 [==============================] - 1s 438us/step - loss: 14200.1342 - val_loss: 12994.0223\n",
            "Epoch 881/1000\n",
            "2304/2304 [==============================] - 1s 425us/step - loss: 14441.8817 - val_loss: 16508.9571\n",
            "Epoch 882/1000\n",
            "2304/2304 [==============================] - 1s 444us/step - loss: 14590.5564 - val_loss: 12704.1016\n",
            "Epoch 883/1000\n",
            "2304/2304 [==============================] - 1s 437us/step - loss: 14141.6053 - val_loss: 14625.2396\n",
            "Epoch 884/1000\n",
            "2304/2304 [==============================] - 1s 377us/step - loss: 14457.2792 - val_loss: 13181.9282\n",
            "Epoch 885/1000\n",
            "2304/2304 [==============================] - 1s 395us/step - loss: 14154.0893 - val_loss: 13142.0646\n",
            "Epoch 886/1000\n",
            "2304/2304 [==============================] - 1s 418us/step - loss: 14099.0075 - val_loss: 12615.8368\n",
            "Epoch 887/1000\n",
            "2304/2304 [==============================] - 1s 416us/step - loss: 14432.0832 - val_loss: 13688.7647\n",
            "Epoch 888/1000\n",
            "2304/2304 [==============================] - 1s 418us/step - loss: 14763.6511 - val_loss: 12546.1383\n",
            "Epoch 889/1000\n",
            "2304/2304 [==============================] - 1s 400us/step - loss: 14257.1427 - val_loss: 15314.1020\n",
            "Epoch 890/1000\n",
            "2304/2304 [==============================] - 1s 407us/step - loss: 14685.3420 - val_loss: 12802.6904\n",
            "Epoch 891/1000\n",
            "2304/2304 [==============================] - 1s 398us/step - loss: 14311.2269 - val_loss: 13009.1204\n",
            "Epoch 892/1000\n",
            "2304/2304 [==============================] - 1s 418us/step - loss: 14441.2347 - val_loss: 13246.5764\n",
            "Epoch 893/1000\n",
            "2304/2304 [==============================] - 1s 421us/step - loss: 13962.6542 - val_loss: 13388.3987\n",
            "Epoch 894/1000\n",
            "2304/2304 [==============================] - 1s 403us/step - loss: 14644.0992 - val_loss: 16022.9132\n",
            "Epoch 895/1000\n",
            "2304/2304 [==============================] - 1s 408us/step - loss: 14487.1708 - val_loss: 13156.4069\n",
            "Epoch 896/1000\n",
            "2304/2304 [==============================] - 1s 422us/step - loss: 14494.2526 - val_loss: 12960.4321\n",
            "Epoch 897/1000\n",
            "2304/2304 [==============================] - 1s 416us/step - loss: 14206.2011 - val_loss: 13049.3552\n",
            "Epoch 898/1000\n",
            "2304/2304 [==============================] - 1s 408us/step - loss: 14461.0843 - val_loss: 13081.9360\n",
            "Epoch 899/1000\n",
            "2304/2304 [==============================] - 1s 418us/step - loss: 14231.0203 - val_loss: 12909.8227\n",
            "Epoch 900/1000\n",
            "2304/2304 [==============================] - 1s 413us/step - loss: 14248.6927 - val_loss: 15215.5780\n",
            "Epoch 901/1000\n",
            "2304/2304 [==============================] - 1s 436us/step - loss: 14475.0888 - val_loss: 12317.9968\n",
            "Epoch 902/1000\n",
            "2304/2304 [==============================] - 1s 424us/step - loss: 14409.6735 - val_loss: 12467.8517\n",
            "Epoch 903/1000\n",
            "2304/2304 [==============================] - 1s 434us/step - loss: 14274.7537 - val_loss: 13747.5079\n",
            "Epoch 904/1000\n",
            "2304/2304 [==============================] - 1s 416us/step - loss: 14452.9215 - val_loss: 12402.7182\n",
            "Epoch 905/1000\n",
            "2304/2304 [==============================] - 1s 410us/step - loss: 14406.0842 - val_loss: 13519.5157\n",
            "Epoch 906/1000\n",
            "2304/2304 [==============================] - 1s 419us/step - loss: 14147.5470 - val_loss: 15100.2449\n",
            "Epoch 907/1000\n",
            "2304/2304 [==============================] - 1s 421us/step - loss: 14430.0315 - val_loss: 13061.8966\n",
            "Epoch 908/1000\n",
            "2304/2304 [==============================] - 1s 392us/step - loss: 14037.1031 - val_loss: 15047.8518\n",
            "Epoch 909/1000\n",
            "2304/2304 [==============================] - 1s 404us/step - loss: 14497.5600 - val_loss: 12198.8537\n",
            "Epoch 910/1000\n",
            "2304/2304 [==============================] - 1s 411us/step - loss: 14366.8323 - val_loss: 14644.8727\n",
            "Epoch 911/1000\n",
            "2304/2304 [==============================] - 1s 408us/step - loss: 14138.7617 - val_loss: 13198.3730\n",
            "Epoch 912/1000\n",
            "2304/2304 [==============================] - 1s 387us/step - loss: 14551.6633 - val_loss: 12640.6007\n",
            "Epoch 913/1000\n",
            "2304/2304 [==============================] - 1s 395us/step - loss: 13842.8162 - val_loss: 13103.7514\n",
            "Epoch 914/1000\n",
            "2304/2304 [==============================] - ETA: 0s - loss: 14027.096 - 1s 406us/step - loss: 14014.5653 - val_loss: 13519.0226\n",
            "Epoch 915/1000\n",
            "2304/2304 [==============================] - 1s 406us/step - loss: 14198.5005 - val_loss: 13368.7286\n",
            "Epoch 916/1000\n",
            "2304/2304 [==============================] - 1s 399us/step - loss: 14822.5560 - val_loss: 15374.5320\n",
            "Epoch 917/1000\n",
            "2304/2304 [==============================] - 1s 402us/step - loss: 14289.0921 - val_loss: 14090.4929\n",
            "Epoch 918/1000\n",
            "2304/2304 [==============================] - 1s 414us/step - loss: 14206.7270 - val_loss: 13044.4802\n",
            "Epoch 919/1000\n",
            "2304/2304 [==============================] - 1s 413us/step - loss: 14460.7795 - val_loss: 13302.6180\n",
            "Epoch 920/1000\n",
            "2304/2304 [==============================] - 1s 433us/step - loss: 14155.9907 - val_loss: 13949.3602\n",
            "Epoch 921/1000\n",
            "2304/2304 [==============================] - 1s 446us/step - loss: 14249.6631 - val_loss: 13610.0707\n",
            "Epoch 922/1000\n",
            "2304/2304 [==============================] - 1s 423us/step - loss: 13840.5041 - val_loss: 13909.9199\n",
            "Epoch 923/1000\n",
            "2304/2304 [==============================] - 1s 417us/step - loss: 13814.5286 - val_loss: 12826.1274\n",
            "Epoch 924/1000\n",
            "2304/2304 [==============================] - 1s 419us/step - loss: 14904.2527 - val_loss: 13254.0662\n",
            "Epoch 925/1000\n",
            "2304/2304 [==============================] - 1s 401us/step - loss: 14411.9720 - val_loss: 12841.3170\n",
            "Epoch 926/1000\n",
            "2304/2304 [==============================] - 1s 406us/step - loss: 14629.6957 - val_loss: 15033.8485\n",
            "Epoch 927/1000\n",
            "2304/2304 [==============================] - 1s 416us/step - loss: 14348.2908 - val_loss: 14876.2320\n",
            "Epoch 928/1000\n",
            "2304/2304 [==============================] - 1s 420us/step - loss: 14075.3151 - val_loss: 13959.1821\n",
            "Epoch 929/1000\n",
            "2304/2304 [==============================] - 1s 409us/step - loss: 14288.5601 - val_loss: 12458.3268\n",
            "Epoch 930/1000\n",
            "2304/2304 [==============================] - 1s 418us/step - loss: 14819.0479 - val_loss: 12861.2873\n",
            "Epoch 931/1000\n",
            "2304/2304 [==============================] - 1s 455us/step - loss: 13920.4318 - val_loss: 12759.2584\n",
            "Epoch 932/1000\n",
            "2304/2304 [==============================] - 1s 410us/step - loss: 14030.5567 - val_loss: 16690.3853\n",
            "Epoch 933/1000\n",
            "2304/2304 [==============================] - 1s 409us/step - loss: 14995.1577 - val_loss: 12408.4145\n",
            "Epoch 934/1000\n",
            "2304/2304 [==============================] - 1s 418us/step - loss: 14364.7210 - val_loss: 13108.9323\n",
            "Epoch 935/1000\n",
            "2304/2304 [==============================] - 1s 413us/step - loss: 14219.7713 - val_loss: 12570.9672\n",
            "Epoch 936/1000\n",
            "2304/2304 [==============================] - 1s 426us/step - loss: 14441.0540 - val_loss: 12885.1096\n",
            "Epoch 937/1000\n",
            "2304/2304 [==============================] - 1s 421us/step - loss: 14052.5804 - val_loss: 12657.4459\n",
            "Epoch 938/1000\n",
            "2304/2304 [==============================] - 1s 445us/step - loss: 13923.9323 - val_loss: 13260.1057\n",
            "Epoch 939/1000\n",
            "2304/2304 [==============================] - 1s 440us/step - loss: 14013.6045 - val_loss: 13729.9309\n",
            "Epoch 940/1000\n",
            "2304/2304 [==============================] - 1s 383us/step - loss: 13959.4256 - val_loss: 12934.7212\n",
            "Epoch 941/1000\n",
            "2304/2304 [==============================] - 1s 429us/step - loss: 14320.5392 - val_loss: 13995.1145\n",
            "Epoch 942/1000\n",
            "2304/2304 [==============================] - ETA: 0s - loss: 14821.987 - 1s 402us/step - loss: 14817.3598 - val_loss: 12546.6118\n",
            "Epoch 943/1000\n",
            "2304/2304 [==============================] - 1s 400us/step - loss: 13632.6041 - val_loss: 12900.9206\n",
            "Epoch 944/1000\n",
            "2304/2304 [==============================] - 1s 392us/step - loss: 14375.1462 - val_loss: 12765.3758\n",
            "Epoch 945/1000\n",
            "2304/2304 [==============================] - 1s 378us/step - loss: 14128.5347 - val_loss: 14432.7357\n",
            "Epoch 946/1000\n",
            "2304/2304 [==============================] - 1s 371us/step - loss: 14197.4131 - val_loss: 13281.8154\n",
            "Epoch 947/1000\n",
            "2304/2304 [==============================] - 1s 373us/step - loss: 14080.5850 - val_loss: 12181.3528\n",
            "Epoch 948/1000\n",
            "2304/2304 [==============================] - 1s 384us/step - loss: 14324.9667 - val_loss: 12349.6915\n",
            "Epoch 949/1000\n",
            "2304/2304 [==============================] - 1s 399us/step - loss: 14012.5511 - val_loss: 13018.6412\n",
            "Epoch 950/1000\n",
            "2304/2304 [==============================] - 1s 390us/step - loss: 14255.0074 - val_loss: 15873.9080\n",
            "Epoch 951/1000\n",
            "2304/2304 [==============================] - 1s 412us/step - loss: 14717.7372 - val_loss: 12762.9510\n",
            "Epoch 952/1000\n",
            "2304/2304 [==============================] - 1s 383us/step - loss: 13974.3436 - val_loss: 12546.4765\n",
            "Epoch 953/1000\n",
            "2304/2304 [==============================] - 1s 372us/step - loss: 14234.0405 - val_loss: 13405.9529\n",
            "Epoch 954/1000\n",
            "2304/2304 [==============================] - 1s 369us/step - loss: 14021.4645 - val_loss: 12466.7760\n",
            "Epoch 955/1000\n",
            "2304/2304 [==============================] - 1s 369us/step - loss: 13925.6977 - val_loss: 13453.8253\n",
            "Epoch 956/1000\n",
            "2304/2304 [==============================] - 1s 369us/step - loss: 14474.5282 - val_loss: 12504.4543\n",
            "Epoch 957/1000\n",
            "2304/2304 [==============================] - 1s 372us/step - loss: 13990.5396 - val_loss: 12301.0943\n",
            "Epoch 958/1000\n",
            "2304/2304 [==============================] - 1s 371us/step - loss: 13936.6069 - val_loss: 13217.6736\n",
            "Epoch 959/1000\n",
            "2304/2304 [==============================] - 1s 374us/step - loss: 14229.4402 - val_loss: 12295.4087\n",
            "Epoch 960/1000\n",
            "2304/2304 [==============================] - 1s 373us/step - loss: 14244.5842 - val_loss: 12878.1249\n",
            "Epoch 961/1000\n",
            "2304/2304 [==============================] - 1s 382us/step - loss: 13966.3603 - val_loss: 13099.1012\n",
            "Epoch 962/1000\n",
            "2304/2304 [==============================] - 1s 377us/step - loss: 14448.5880 - val_loss: 13052.2593\n",
            "Epoch 963/1000\n",
            "2304/2304 [==============================] - 1s 377us/step - loss: 13804.9836 - val_loss: 13043.3453\n",
            "Epoch 964/1000\n",
            "2304/2304 [==============================] - 1s 377us/step - loss: 14432.2674 - val_loss: 12421.3675\n",
            "Epoch 965/1000\n",
            "2304/2304 [==============================] - 1s 389us/step - loss: 13866.9203 - val_loss: 12710.0364\n",
            "Epoch 966/1000\n",
            "2304/2304 [==============================] - 1s 383us/step - loss: 14118.5367 - val_loss: 12608.4325\n",
            "Epoch 967/1000\n",
            "2304/2304 [==============================] - 1s 383us/step - loss: 13863.9051 - val_loss: 12497.9934\n",
            "Epoch 968/1000\n",
            "2304/2304 [==============================] - 1s 382us/step - loss: 14055.5219 - val_loss: 12798.6343\n",
            "Epoch 969/1000\n",
            "2304/2304 [==============================] - 1s 382us/step - loss: 14203.0176 - val_loss: 12626.2237\n",
            "Epoch 970/1000\n",
            "2304/2304 [==============================] - 1s 370us/step - loss: 14280.9816 - val_loss: 12754.1671\n",
            "Epoch 971/1000\n",
            "2304/2304 [==============================] - 1s 373us/step - loss: 13951.1702 - val_loss: 12712.6477\n",
            "Epoch 972/1000\n",
            "2304/2304 [==============================] - 1s 383us/step - loss: 14304.2816 - val_loss: 17329.0146\n",
            "Epoch 973/1000\n",
            "2304/2304 [==============================] - 1s 371us/step - loss: 15169.8071 - val_loss: 12271.1659\n",
            "Epoch 974/1000\n",
            "2304/2304 [==============================] - 1s 384us/step - loss: 14481.7509 - val_loss: 13241.9281\n",
            "Epoch 975/1000\n",
            "2304/2304 [==============================] - 1s 374us/step - loss: 13924.4217 - val_loss: 13457.2602\n",
            "Epoch 976/1000\n",
            "2304/2304 [==============================] - 1s 374us/step - loss: 14402.3264 - val_loss: 12988.4250\n",
            "Epoch 977/1000\n",
            "2304/2304 [==============================] - 1s 373us/step - loss: 13917.5887 - val_loss: 14214.5680\n",
            "Epoch 978/1000\n",
            "2304/2304 [==============================] - 1s 374us/step - loss: 13851.6644 - val_loss: 14613.6863\n",
            "Epoch 979/1000\n",
            "2304/2304 [==============================] - 1s 375us/step - loss: 13638.6078 - val_loss: 12895.8128\n",
            "Epoch 980/1000\n",
            "2304/2304 [==============================] - 1s 371us/step - loss: 14048.2012 - val_loss: 15794.4410\n",
            "Epoch 981/1000\n",
            "2304/2304 [==============================] - 1s 377us/step - loss: 14248.7375 - val_loss: 12595.4897\n",
            "Epoch 982/1000\n",
            "2304/2304 [==============================] - 1s 378us/step - loss: 13976.9222 - val_loss: 12944.9743\n",
            "Epoch 983/1000\n",
            "2304/2304 [==============================] - 1s 380us/step - loss: 13878.1132 - val_loss: 14461.1452\n",
            "Epoch 984/1000\n",
            "2304/2304 [==============================] - 1s 377us/step - loss: 13750.8418 - val_loss: 13647.0555\n",
            "Epoch 985/1000\n",
            "2304/2304 [==============================] - 1s 383us/step - loss: 13821.2843 - val_loss: 15657.8466\n",
            "Epoch 986/1000\n",
            "2304/2304 [==============================] - 1s 387us/step - loss: 13951.3668 - val_loss: 12503.4262\n",
            "Epoch 987/1000\n",
            "2304/2304 [==============================] - 1s 374us/step - loss: 13732.6873 - val_loss: 12674.2793\n",
            "Epoch 988/1000\n",
            "2304/2304 [==============================] - 1s 384us/step - loss: 14143.0375 - val_loss: 12801.1951\n",
            "Epoch 989/1000\n",
            "2304/2304 [==============================] - 1s 376us/step - loss: 14586.6882 - val_loss: 13891.1528\n",
            "Epoch 990/1000\n",
            "2304/2304 [==============================] - 1s 376us/step - loss: 14043.9540 - val_loss: 12848.9969\n",
            "Epoch 991/1000\n",
            "2304/2304 [==============================] - 1s 383us/step - loss: 14709.4745 - val_loss: 13196.8980\n",
            "Epoch 992/1000\n",
            "2304/2304 [==============================] - 1s 379us/step - loss: 13989.1206 - val_loss: 13358.9111\n",
            "Epoch 993/1000\n",
            "2304/2304 [==============================] - 1s 373us/step - loss: 13895.6108 - val_loss: 12177.6148\n",
            "Epoch 994/1000\n",
            "2304/2304 [==============================] - 1s 377us/step - loss: 13983.3783 - val_loss: 12892.7427\n",
            "Epoch 995/1000\n",
            "2304/2304 [==============================] - 1s 377us/step - loss: 14490.0895 - val_loss: 14749.1190\n",
            "Epoch 996/1000\n",
            "2304/2304 [==============================] - 1s 376us/step - loss: 14125.6700 - val_loss: 13738.9878\n",
            "Epoch 997/1000\n",
            "2304/2304 [==============================] - 1s 388us/step - loss: 14066.8977 - val_loss: 12453.9828\n",
            "Epoch 998/1000\n",
            "2304/2304 [==============================] - 1s 388us/step - loss: 13551.5174 - val_loss: 14619.2152\n",
            "Epoch 999/1000\n",
            "2304/2304 [==============================] - 1s 386us/step - loss: 13681.4783 - val_loss: 12727.4434\n",
            "Epoch 1000/1000\n",
            "2304/2304 [==============================] - 1s 383us/step - loss: 14083.6308 - val_loss: 13065.0160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg13gBoDzRNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ann_pred=classifier.predict(df_Test.drop(['SalePrice'],axis=1).values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdaK1Oa9zRNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpSoVtoRzRNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}